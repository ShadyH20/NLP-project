{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadyH20/NLP-project/blob/main/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: farasa in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (0.0.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: farasapy in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (0.0.14)\n",
            "Requirement already satisfied: requests in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from farasapy) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from farasapy) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from requests->farasapy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from requests->farasapy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from requests->farasapy) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from requests->farasapy) (2024.2.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: arabic-reshaper in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (3.0.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: python-bidi in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (0.6.6)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: qalsadi in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (0.5)\n",
            "Requirement already satisfied: Arabic-Stopwords>=0.4.2 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from qalsadi) (0.4.3)\n",
            "Requirement already satisfied: alyahmor>=0.2 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from qalsadi) (0.2)\n",
            "Requirement already satisfied: arramooz-pysqlite>=0.4.2 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from qalsadi) (0.4.2)\n",
            "Requirement already satisfied: codernitydb3 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from qalsadi) (0.6.0)\n",
            "Requirement already satisfied: libqutrub>=1.2.3 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from qalsadi) (1.2.4.1)\n",
            "Requirement already satisfied: mysam-tagmanager>=0.3.3 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from qalsadi) (0.4)\n",
            "Requirement already satisfied: naftawayh>=0.3 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from qalsadi) (0.4)\n",
            "Requirement already satisfied: pickledb>=0.9.2 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from qalsadi) (1.3.2)\n",
            "Requirement already satisfied: pyarabic>=0.6.7 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from qalsadi) (0.6.15)\n",
            "Requirement already satisfied: tashaphyne>=0.3.4.1 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from qalsadi) (0.3.6)\n",
            "Requirement already satisfied: orjson in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from pickledb>=0.9.2->qalsadi) (3.10.15)\n",
            "Requirement already satisfied: aiofiles in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from pickledb>=0.9.2->qalsadi) (24.1.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from pyarabic>=0.6.7->qalsadi) (1.15.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langdetect in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (1.0.9)\n",
            "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from langdetect) (1.15.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: googletrans in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (4.0.2)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: anyio in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.3.0)\n",
            "Requirement already satisfied: certifi in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.4)\n",
            "Requirement already satisfied: idna in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.12.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install farasa\n",
        "!pip install farasapy\n",
        "!pip install arabic-reshaper\n",
        "!pip install python-bidi\n",
        "!pip install qalsadi\n",
        "!pip install langdetect\n",
        "!pip install googletrans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/sherifahammoud/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/sherifahammoud/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/sherifahammoud/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/sherifahammoud/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /Users/sherifahammoud/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/sherifahammoud/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/sherifahammoud/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from itertools import islice\n",
        "from nltk.util import ngrams\n",
        "import arabic_reshaper\n",
        "from bidi.algorithm import get_display\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from farasa.segmenter import FarasaSegmenter\n",
        "from farasa.stemmer import FarasaStemmer\n",
        "from qalsadi.lemmatizer import Lemmatizer\n",
        "from langdetect import detect\n",
        "from googletrans import Translator\n",
        "from tashaphyne.stemming import ArabicLightStemmer\n",
        "from farasa.diacratizer import FarasaDiacritizer\n",
        "from qalsadi.lemmatizer import Lemmatizer\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "from nltk import tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unlabeled Data (Da7ee7, Elsaha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "8BS8I-FnoSI0"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"./YoutubeChannels\"\n",
        "CHANNELS = [\"Da7ee7\", \"Elsaha\"]\n",
        "data = []\n",
        "\n",
        "timestamp_pattern = re.compile(r\"^\\d+\\.\\d+:\\s*\")  # Removes timestamps at start of lines\n",
        "\n",
        "for channel in CHANNELS:\n",
        "    raw_data_path = os.path.join(BASE_DIR, channel, \"Raw Data\")\n",
        "    \n",
        "    if os.path.exists(raw_data_path):\n",
        "        for file_name in os.listdir(raw_data_path):\n",
        "            if file_name.endswith(\".txt\"):\n",
        "                file_path = os.path.join(raw_data_path, file_name)\n",
        "                \n",
        "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    raw_lines = f.readlines()\n",
        "                \n",
        "                # Remove timestamps and extra whitespace from lines\n",
        "                cleaned_text = \"\\n\".join(re.sub(timestamp_pattern, \"\", line).strip() for line in raw_lines)\n",
        "                episode_title = file_name.replace(\".txt\", \"\").strip()\n",
        "                \n",
        "                # Append the entire script as one row\n",
        "                data.append([channel, episode_title, cleaned_text, \"\", \"\"])\n",
        "\n",
        "# Create DataFrame\n",
        "unlabelled_df = pd.DataFrame(data, columns=[\"Channel\", \"EpisodeTitle\", \"Original Script\", \"Processed Script\", \"Category\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Labeled Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_DIR = \"./YoutubeChannels\"\n",
        "LABELLED_CHANNELS_1 = [\"Kefaya Ba2a\", \"Business Bel Araby\", \"B Hodoo2\"]\n",
        "LABELLED_CHANNELS_2 = [\"Eqtisad_Al_Hadaraa\", \"Fi_Al_Hadaraa\", \"Al_Mokhbir_Al_Eqtisadi\"]\n",
        "LABELLED_CHANNELS_3 = [\"Akhdar\"]\n",
        "data = []\n",
        "\n",
        "def process_labelled_channel_1(channel):\n",
        "    raw_data_path = os.path.join(BASE_DIR, channel, \"raw\")\n",
        "    annotations_path = os.path.join(BASE_DIR, channel, \"annotations.json\")\n",
        "    \n",
        "    if os.path.exists(annotations_path):\n",
        "        with open(annotations_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            annotations = json.load(f)\n",
        "        \n",
        "        metadata_map = {\n",
        "            item[\"title\"].strip()[:10] if channel == \"B Hodoo2\" else item[\"title\"].strip(): item\n",
        "            for item in annotations\n",
        "        }\n",
        "        \n",
        "        if os.path.exists(raw_data_path):\n",
        "            for file_name in os.listdir(raw_data_path):\n",
        "                if file_name.endswith(\".txt\"):\n",
        "                    file_path = os.path.join(raw_data_path, file_name)\n",
        "                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                        raw_text = f.read().strip()\n",
        "                    \n",
        "                    episode_title = file_name.replace(\".txt\", \"\").strip()\n",
        "                    match_key = episode_title[:10] if channel == \"B Hodoo2\" else episode_title\n",
        "                    metadata = metadata_map.get(match_key, {})\n",
        "                    \n",
        "                    data.append([\n",
        "                        channel,\n",
        "                        episode_title,\n",
        "                        raw_text,\n",
        "                        \"\",\n",
        "                        metadata.get(\"dialogue\", \"\"),\n",
        "                        metadata.get(\"type\", \"\"),\n",
        "                        metadata.get(\"length\", \"\"),\n",
        "                        metadata.get(\"category\", \"\")\n",
        "                    ])\n",
        "\n",
        "def process_labelled_channel_2(channel):\n",
        "    raw_data_path = os.path.join(BASE_DIR, channel, \"raw_data\")\n",
        "    metadata_path = os.path.join(BASE_DIR, channel, \"metadata\")\n",
        "    \n",
        "    if os.path.exists(raw_data_path) and os.path.exists(metadata_path):\n",
        "        for file_name in os.listdir(raw_data_path):\n",
        "            if file_name.endswith(\".txt\"):\n",
        "                episode_title = file_name.replace(\".txt\", \"\").strip()\n",
        "                raw_file_path = os.path.join(raw_data_path, file_name)\n",
        "                metadata_file_path = os.path.join(metadata_path, episode_title + \".json\")\n",
        "                \n",
        "                with open(raw_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    raw_text = f.read().strip()\n",
        "                \n",
        "                if os.path.exists(metadata_file_path):\n",
        "                    with open(metadata_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                        metadata = json.load(f)\n",
        "                    category = metadata.get(\"categories\", [\"\"])[0]\n",
        "                    \n",
        "                    data.append([\n",
        "                        channel,\n",
        "                        episode_title,\n",
        "                        raw_text,\n",
        "                        \"\",\n",
        "                        metadata.get(\"dialogue\", \"\"),\n",
        "                        metadata.get(\"type\", \"\"),\n",
        "                        metadata.get(\"length\", \"\"),\n",
        "                        category\n",
        "                    ])\n",
        "\n",
        "def find_akhdar_raw_and_metadata(path):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        if \"raw_data\" in dirs and \"metadata\" in dirs:\n",
        "            process_labelled_channel_2(root)\n",
        "\n",
        "def process_labelled_channel_3(channel):\n",
        "    base_path = os.path.join(BASE_DIR, channel)\n",
        "    find_akhdar_raw_and_metadata(base_path)\n",
        "\n",
        "# Process all channels\n",
        "for channel in LABELLED_CHANNELS_1:\n",
        "    process_labelled_channel_1(channel)\n",
        "\n",
        "for channel in LABELLED_CHANNELS_2:\n",
        "    process_labelled_channel_2(channel)\n",
        "\n",
        "for channel in LABELLED_CHANNELS_3:\n",
        "    process_labelled_channel_3(channel)\n",
        "\n",
        "labelled_df = pd.DataFrame(data, columns=[\"Channel\", \"Episode Title\", \"Original Script\", \"Processed Script\", \"Dialogue\", \"Type\", \"Length\", \"Category\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Loading Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ Checking Unlabelled DataFrame:\n",
            "ğŸ“Œ Sample rows from channel: Da7ee7\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>EpisodeTitle</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Da7ee7</td>\n",
              "      <td>Ù†Ø§Ø¨Ù„ÙŠÙˆÙ† ÙÙŠ Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©  Ø§Ù„Ø¯Ø­ÙŠØ­</td>\n",
              "      <td>ÙŠØ§ Ø¨ÙˆÙŠ! Ø¯Ø§ Ø£Ù†ÙŠ ØªØ¹Ø¨Øª Ø¬ÙˆÙŠ!\\n!Bonjour\\nØ£ÙÙ†Ø¯Ù…ØŸ!\\nP...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Da7ee7</td>\n",
              "      <td>Ù‡Ø§Ù†ÙŠØ¨Ø§Ù„  Ø§Ù„Ø¯Ø­ÙŠØ­</td>\n",
              "      <td>Ø£ÙˆÙ‡ØŒ \"Ù…Ø§Ø±ÙƒÙŠÙ†ÙˆØ³\"ØŒ Ù„Ù… Ø£Ø¹ÙØ¯ Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ù„Ù†ÙˆÙ…ØŒ\\nÙ…Ù† ÙØ±Ø·...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Da7ee7</td>\n",
              "      <td>ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ´Ø±ÙŠØ­  Ø§Ù„Ø¯Ø­ÙŠØ­</td>\n",
              "      <td>Ø£Ù†Ø§ Ø§Ù„Ø¯ÙƒØªÙˆØ± \"ÙŠØ§Ø³Ø± Ø§Ù„Ø·Ø§Ø¦ÙŠ\"ØŒ\\nØ£ÙƒØªØ¨ Ø§Ù„Ø¢Ù† ØªÙ‚Ø±ÙŠØ± ØªØ´...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Channel                EpisodeTitle  \\\n",
              "54  Da7ee7  Ù†Ø§Ø¨Ù„ÙŠÙˆÙ† ÙÙŠ Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©  Ø§Ù„Ø¯Ø­ÙŠØ­   \n",
              "6   Da7ee7             Ù‡Ø§Ù†ÙŠØ¨Ø§Ù„  Ø§Ù„Ø¯Ø­ÙŠØ­   \n",
              "1   Da7ee7       ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ´Ø±ÙŠØ­  Ø§Ù„Ø¯Ø­ÙŠØ­   \n",
              "\n",
              "                                      Original Script Processed Script  \\\n",
              "54  ÙŠØ§ Ø¨ÙˆÙŠ! Ø¯Ø§ Ø£Ù†ÙŠ ØªØ¹Ø¨Øª Ø¬ÙˆÙŠ!\\n!Bonjour\\nØ£ÙÙ†Ø¯Ù…ØŸ!\\nP...                    \n",
              "6   Ø£ÙˆÙ‡ØŒ \"Ù…Ø§Ø±ÙƒÙŠÙ†ÙˆØ³\"ØŒ Ù„Ù… Ø£Ø¹ÙØ¯ Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ù„Ù†ÙˆÙ…ØŒ\\nÙ…Ù† ÙØ±Ø·...                    \n",
              "1   Ø£Ù†Ø§ Ø§Ù„Ø¯ÙƒØªÙˆØ± \"ÙŠØ§Ø³Ø± Ø§Ù„Ø·Ø§Ø¦ÙŠ\"ØŒ\\nØ£ÙƒØªØ¨ Ø§Ù„Ø¢Ù† ØªÙ‚Ø±ÙŠØ± ØªØ´...                    \n",
              "\n",
              "   Category  \n",
              "54           \n",
              "6            \n",
              "1            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "ğŸ“Œ Sample rows from channel: Elsaha\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>EpisodeTitle</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Elsaha</td>\n",
              "      <td>Ø£Ù‚ÙˆÙ‰ Ù…Ù† Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¥Ø¹Ø§Ù‚Ø©.. Ø­ÙƒØ§ÙŠØ© Ø¹Ø¨Ø¯ Ø§Ù„Ø±Ø­Ù…Ù† ØµÙ„Ø§Ø­</td>\n",
              "      <td>[Ù…ÙˆØ³ÙŠÙ‚Ù‰]\\nØ§ÙˆÙ„ Ù…Ø§ Ù„Ø¨Ø³Øª Ø§Ù„Ø·Ø±Ù Ø·Ø¨Ø¹Ø§ ÙƒØ§Ù† Ù…Ø¶Ø§ÙŠÙ‚Ù†ÙŠ Ø¨...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>Elsaha</td>\n",
              "      <td>Ù„ÙŠØ³Øª Ø¯ÙŠÙ†ÙŠØ© Ù…Ø³ÙŠØ­ÙŠØ©.. Ø­ÙƒØ§ÙŠØ© Ø¬Ø±ÙŠØ¯Ø© ÙˆØ·Ù†ÙŠ</td>\n",
              "      <td>ÙˆØ·Ù†ÙŠ ØµØ¯Ø±Øª\\n1958 ÙˆØ§Ù†Ø§ ÙƒØ§Ù† Ø³Ù†ÙŠ Ø«Ù…Ø§Ù† Ø³Ù†ÙŠÙ† ÙˆØ§Ù„Ø¯ÙŠ Ø§...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>Elsaha</td>\n",
              "      <td>ÙˆØ§ØªØ± Ø§Ù„Ø¨Ø­Ø±ÙŠ.. Ù…ØµÙˆØ± Ø­ÙŠØ§Ø© Ø·Ø¨ÙŠØ¹ÙŠØ©</td>\n",
              "      <td>Ø§ÙŠ Ù…ØµÙˆØ± Ø­ÙŠØ§Ù‡ Ø¨Ø±ÙŠÙ‡ ÙŠÙ‚ÙˆÙ„ Ù„Ùƒ Ù„Ùˆ Ø§Ù†Øª Ø±Ø§ÙŠØ­\\nØªØµÙˆØ± Ø·ÙŠ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Channel                                    EpisodeTitle  \\\n",
              "163  Elsaha  Ø£Ù‚ÙˆÙ‰ Ù…Ù† Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¥Ø¹Ø§Ù‚Ø©.. Ø­ÙƒØ§ÙŠØ© Ø¹Ø¨Ø¯ Ø§Ù„Ø±Ø­Ù…Ù† ØµÙ„Ø§Ø­   \n",
              "159  Elsaha            Ù„ÙŠØ³Øª Ø¯ÙŠÙ†ÙŠØ© Ù…Ø³ÙŠØ­ÙŠØ©.. Ø­ÙƒØ§ÙŠØ© Ø¬Ø±ÙŠØ¯Ø© ÙˆØ·Ù†ÙŠ   \n",
              "154  Elsaha                  ÙˆØ§ØªØ± Ø§Ù„Ø¨Ø­Ø±ÙŠ.. Ù…ØµÙˆØ± Ø­ÙŠØ§Ø© Ø·Ø¨ÙŠØ¹ÙŠØ©   \n",
              "\n",
              "                                       Original Script Processed Script  \\\n",
              "163  [Ù…ÙˆØ³ÙŠÙ‚Ù‰]\\nØ§ÙˆÙ„ Ù…Ø§ Ù„Ø¨Ø³Øª Ø§Ù„Ø·Ø±Ù Ø·Ø¨Ø¹Ø§ ÙƒØ§Ù† Ù…Ø¶Ø§ÙŠÙ‚Ù†ÙŠ Ø¨...                    \n",
              "159  ÙˆØ·Ù†ÙŠ ØµØ¯Ø±Øª\\n1958 ÙˆØ§Ù†Ø§ ÙƒØ§Ù† Ø³Ù†ÙŠ Ø«Ù…Ø§Ù† Ø³Ù†ÙŠÙ† ÙˆØ§Ù„Ø¯ÙŠ Ø§...                    \n",
              "154  Ø§ÙŠ Ù…ØµÙˆØ± Ø­ÙŠØ§Ù‡ Ø¨Ø±ÙŠÙ‡ ÙŠÙ‚ÙˆÙ„ Ù„Ùƒ Ù„Ùˆ Ø§Ù†Øª Ø±Ø§ÙŠØ­\\nØªØµÙˆØ± Ø·ÙŠ...                    \n",
              "\n",
              "    Category  \n",
              "163           \n",
              "159           \n",
              "154           "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ğŸ“ Checking Labelled DataFrame:\n",
            "ğŸ“Œ Sample rows from channel: Kefaya Ba2a\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>Episode Title</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Dialogue</th>\n",
              "      <th>Type</th>\n",
              "      <th>Length</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Kefaya Ba2a</td>\n",
              "      <td>Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ â€œØ¨Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙƒâ€ - Ø§Ù„Ø¹Ø³Ù Ø§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠ</td>\n",
              "      <td>Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ù†Ø³Ø®Ù‡\\nØ§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠ...</td>\n",
              "      <td></td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kefaya Ba2a</td>\n",
              "      <td>Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ - ØªØ´ÙŠØ² ÙƒÙŠÙƒ Ø¨Ø¯ÙˆÙ† ØªØ´ÙŠØ²</td>\n",
              "      <td>Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª\\nØ¯Ù‡ ÙŠØ§...</td>\n",
              "      <td></td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Kefaya Ba2a</td>\n",
              "      <td>Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ - ÙƒØ§ØªØ´ Ø¹Ù„ÙŠÙ‡ Ù¡</td>\n",
              "      <td>Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª\\nØ¯Ù‡ ÙŠØ§...</td>\n",
              "      <td></td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Channel                                    Episode Title  \\\n",
              "16  Kefaya Ba2a  Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ â€œØ¨Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙƒâ€ - Ø§Ù„Ø¹Ø³Ù Ø§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠ   \n",
              "2   Kefaya Ba2a           Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ - ØªØ´ÙŠØ² ÙƒÙŠÙƒ Ø¨Ø¯ÙˆÙ† ØªØ´ÙŠØ²   \n",
              "5   Kefaya Ba2a                  Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ - ÙƒØ§ØªØ´ Ø¹Ù„ÙŠÙ‡ Ù¡   \n",
              "\n",
              "                                      Original Script Processed Script  \\\n",
              "16  Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ù†Ø³Ø®Ù‡\\nØ§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠ...                    \n",
              "2   Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª\\nØ¯Ù‡ ÙŠØ§...                    \n",
              "5   Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª\\nØ¯Ù‡ ÙŠØ§...                    \n",
              "\n",
              "   Dialogue     Type Length        Category  \n",
              "16    false  Podcast         People & Blogs  \n",
              "2     false  Podcast         People & Blogs  \n",
              "5     false  Podcast         People & Blogs  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "ğŸ“Œ Sample rows from channel: Business Bel Araby\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>Episode Title</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Dialogue</th>\n",
              "      <th>Type</th>\n",
              "      <th>Length</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Business Bel Araby</td>\n",
              "      <td>Ù…Ø§ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù†Ø¬Ø§Ø­ #2</td>\n",
              "      <td>Ø§ÙŠÙ‡ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù†Ø¬Ø§Ø­ Ø¨Ø§Ù„Ù†Ø³Ø¨Ù‡ Ù„Ùƒ ÙÙŠ Ø§Ù„Ø­ÙŠØ§Ù‡\\nØ¹Ø§Ù…Ù‡ Ø¹Ø§Ø±...</td>\n",
              "      <td></td>\n",
              "      <td>true</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>Education</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Business Bel Araby</td>\n",
              "      <td>Ù…Ù† Ø·ÙŠØ§Ø± Ø§Ù„ÙŠ Ø±Ø§Ø¦Ø¯ Ø§Ø¹Ù…Ø§Ù„ Ù‚ØµØ© Ù…Ø­Ù…Ø¯ Ø¹Ø§ØµÙŠ Ù…Ø¤Ø³Ø³ Ø¨Ø±Ø§Ù†...</td>\n",
              "      <td>ÙŠØ¹Ù†ÙŠ Ø§ÙˆÙ„ Ø­Ø§Ø¬Ù‡ Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† ÙÙŠ ÙÙƒØ±Ù‡ Ù„ÙŠÙ‡ Ø¹Ø´Ø§Ù†\\nØ§Ù†Øª ...</td>\n",
              "      <td></td>\n",
              "      <td>true</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>Education</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Business Bel Araby</td>\n",
              "      <td>Ù…Ù† Ù…Ù‡Ù†Ø¯Ø³ Ø§Ù„Ù‰ Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ø¯Ø§Ø±Ø© Ù„Ø´Ø±ÙƒØ© Ù…Ù‚Ø§ÙˆÙ„Ø§Øª - Ø·...</td>\n",
              "      <td>Ø§ÙˆØ­Ø´ Ø­Ø§Ø¬Ù‡ ØªØ¹Ù…Ù„Ù‡Ø§ Ù„Ù†ÙØ³Ùƒ Ø§Ù† Ø§Ù†Øª ÙˆØ§Ù†Øª Ù†Ø§Ø²Ù„\\nØ§Ù„Ø´ØºÙ„...</td>\n",
              "      <td></td>\n",
              "      <td>true</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Channel                                      Episode Title  \\\n",
              "22  Business Bel Araby                                  Ù…Ø§ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù†Ø¬Ø§Ø­ #2   \n",
              "25  Business Bel Araby  Ù…Ù† Ø·ÙŠØ§Ø± Ø§Ù„ÙŠ Ø±Ø§Ø¦Ø¯ Ø§Ø¹Ù…Ø§Ù„ Ù‚ØµØ© Ù…Ø­Ù…Ø¯ Ø¹Ø§ØµÙŠ Ù…Ø¤Ø³Ø³ Ø¨Ø±Ø§Ù†...   \n",
              "23  Business Bel Araby  Ù…Ù† Ù…Ù‡Ù†Ø¯Ø³ Ø§Ù„Ù‰ Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ø¯Ø§Ø±Ø© Ù„Ø´Ø±ÙƒØ© Ù…Ù‚Ø§ÙˆÙ„Ø§Øª - Ø·...   \n",
              "\n",
              "                                      Original Script Processed Script  \\\n",
              "22  Ø§ÙŠÙ‡ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù†Ø¬Ø§Ø­ Ø¨Ø§Ù„Ù†Ø³Ø¨Ù‡ Ù„Ùƒ ÙÙŠ Ø§Ù„Ø­ÙŠØ§Ù‡\\nØ¹Ø§Ù…Ù‡ Ø¹Ø§Ø±...                    \n",
              "25  ÙŠØ¹Ù†ÙŠ Ø§ÙˆÙ„ Ø­Ø§Ø¬Ù‡ Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† ÙÙŠ ÙÙƒØ±Ù‡ Ù„ÙŠÙ‡ Ø¹Ø´Ø§Ù†\\nØ§Ù†Øª ...                    \n",
              "23  Ø§ÙˆØ­Ø´ Ø­Ø§Ø¬Ù‡ ØªØ¹Ù…Ù„Ù‡Ø§ Ù„Ù†ÙØ³Ùƒ Ø§Ù† Ø§Ù†Øª ÙˆØ§Ù†Øª Ù†Ø§Ø²Ù„\\nØ§Ù„Ø´ØºÙ„...                    \n",
              "\n",
              "   Dialogue     Type Length        Category  \n",
              "22     true  Podcast              Education  \n",
              "25     true  Podcast              Education  \n",
              "23     true  Podcast         People & Blogs  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "ğŸ“Œ Sample rows from channel: B Hodoo2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>Episode Title</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Dialogue</th>\n",
              "      <th>Type</th>\n",
              "      <th>Length</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>B Hodoo2</td>\n",
              "      <td>Ø²Ø¯Øª Ù¢Ù  ÙƒÙŠÙ„Ùˆ Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø­Ø³Ø¯ _ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ø¨Ù‡Ø¯ÙˆØ¡ Ù…Ø¹ ÙƒØ±ÙŠÙ…...</td>\n",
              "      <td>Ù…Ù† Ø­ÙˆØ§Ù„ÙŠ Ø³Ø¨Ø¹ Ø³Ù†ÙŠÙ† ÙˆØ§Ø­Ø¯Ù‡ ÙƒØªØ¨Øª Ù„ÙŠ ÙÙŠ\\nØ§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª ...</td>\n",
              "      <td></td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>Education</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>B Hodoo2</td>\n",
              "      <td>Ù© Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© ØºÙŠØ±Øª Ø­ÙŠØ§ØªÙŠ - Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„...</td>\n",
              "      <td>Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆØ±Ø­Ù…Ù‡ Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªÙ‡ Ø¯ÙŠ Ù†ØµØ§Ø¦Ø­\\nØ§Ù„ØªÙ„...</td>\n",
              "      <td></td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>Education</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>B Hodoo2</td>\n",
              "      <td>ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø³Ù„Ø¨ÙŠ ÙˆØ§Ù„ØªÙ†Ù…Ø±! _ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ø¨Ù‡Ø¯ÙˆØ¡...</td>\n",
              "      <td>ÙŠØ¯Ø®Ù„ Ø§Ù„Ø¨ÙŠØª ÙØ¨ÙŠÙ‚ÙˆÙ„ Ù„Ù‡Ø§\\nÙˆØµÙÙŠ Ù„ÙŠ Ø§Ù„Ø­Ø±Ø§Ù…ÙŠ Ø¨ÙˆÙ„ÙŠØ³ Ø¨...</td>\n",
              "      <td></td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>Education</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Channel                                      Episode Title  \\\n",
              "39  B Hodoo2  Ø²Ø¯Øª Ù¢Ù  ÙƒÙŠÙ„Ùˆ Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø­Ø³Ø¯ _ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ø¨Ù‡Ø¯ÙˆØ¡ Ù…Ø¹ ÙƒØ±ÙŠÙ…...   \n",
              "41  B Hodoo2  Ù© Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© ØºÙŠØ±Øª Ø­ÙŠØ§ØªÙŠ - Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„...   \n",
              "47  B Hodoo2  ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø³Ù„Ø¨ÙŠ ÙˆØ§Ù„ØªÙ†Ù…Ø±! _ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ø¨Ù‡Ø¯ÙˆØ¡...   \n",
              "\n",
              "                                      Original Script Processed Script  \\\n",
              "39  Ù…Ù† Ø­ÙˆØ§Ù„ÙŠ Ø³Ø¨Ø¹ Ø³Ù†ÙŠÙ† ÙˆØ§Ø­Ø¯Ù‡ ÙƒØªØ¨Øª Ù„ÙŠ ÙÙŠ\\nØ§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª ...                    \n",
              "41  Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆØ±Ø­Ù…Ù‡ Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªÙ‡ Ø¯ÙŠ Ù†ØµØ§Ø¦Ø­\\nØ§Ù„ØªÙ„...                    \n",
              "47  ÙŠØ¯Ø®Ù„ Ø§Ù„Ø¨ÙŠØª ÙØ¨ÙŠÙ‚ÙˆÙ„ Ù„Ù‡Ø§\\nÙˆØµÙÙŠ Ù„ÙŠ Ø§Ù„Ø­Ø±Ø§Ù…ÙŠ Ø¨ÙˆÙ„ÙŠØ³ Ø¨...                    \n",
              "\n",
              "   Dialogue     Type Length   Category  \n",
              "39    false  Podcast         Education  \n",
              "41    false  Podcast         Education  \n",
              "47    false  Podcast         Education  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "ğŸ“Œ Sample rows from channel: Fi_Al_Hadaraa\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>Episode Title</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Dialogue</th>\n",
              "      <th>Type</th>\n",
              "      <th>Length</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Fi_Al_Hadaraa</td>\n",
              "      <td>Ù‡Ø§Ù„Ø§Ù†Ø¯_ØªØ±ÙŠØ¨Ù„_ÙƒØ§Ø¨ØªÙ†__ÙÙŠ_Ø§Ù„Ø­Ø¶Ø§Ø±Ø©</td>\n",
              "      <td>ÙŠØ¹Ù†ÙŠ Ø®Ù„Ø§ØµØŸ\\nÙ…Ø§ ÙÙŠØ´ Ù…Ù†Ù‘Ù‡ ØªØ§Ù†ÙŠØŸ\\nÙ…Ø§ Ø®Ù„Ø§Øµ Ø¨Ù‚Ù‰ ÙŠØ§ ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:24:18</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>Fi_Al_Hadaraa</td>\n",
              "      <td>Ù„Ù…Ø§Ø°Ø§_Ù†Ø­ØªØ§Ø¬_Ø§Ù„ØªØ¹Ù„Ù…_Ø¨Ø´ÙƒÙ„_Ù…Ø³ØªÙ…Ø±_Ù„Ù„Ø­ÙØ§Ø¸_Ø¹Ù„Ù‰_Ø§Ù„ÙˆØ¸ÙŠÙØ©</td>\n",
              "      <td>Ø¯Ù„ÙˆÙ‚ØªÙŠ Ø§Ù„Ù…Ø¤Ø³Ø³Ø§Øª ÙˆØ§Ù„Ø´Ø±ÙƒØ§Øª Ø¨Ù‚Øª Ù…Ø®Ù„ÙŠÙ‡Ø§\\nÙ…Ø³Ø§Ù„Ù‡ ØªØ¯Ø±...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:00:58</td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Fi_Al_Hadaraa</td>\n",
              "      <td>Ø§Ù„Ù„ØºØ©__ÙƒÙŠÙ_ÙÙ‚Ø¯Ù†Ø§_Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©_Ù„Ù„ØºØ©_Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©__ÙÙŠ_Ø§Ù„Ø­...</td>\n",
              "      <td>ÙŠØ§ Ù†Ø¬Ù Ø¨Ù†Ù‘ÙˆØ±ØŒ ØµØ¯ÙŠÙ‚ÙŠ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†. ØµØ¯ÙŠÙ‚ÙŠ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†!\\nØ§...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:17:23</td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Channel                                      Episode Title  \\\n",
              "94  Fi_Al_Hadaraa                     Ù‡Ø§Ù„Ø§Ù†Ø¯_ØªØ±ÙŠØ¨Ù„_ÙƒØ§Ø¨ØªÙ†__ÙÙŠ_Ø§Ù„Ø­Ø¶Ø§Ø±Ø©   \n",
              "85  Fi_Al_Hadaraa   Ù„Ù…Ø§Ø°Ø§_Ù†Ø­ØªØ§Ø¬_Ø§Ù„ØªØ¹Ù„Ù…_Ø¨Ø´ÙƒÙ„_Ù…Ø³ØªÙ…Ø±_Ù„Ù„Ø­ÙØ§Ø¸_Ø¹Ù„Ù‰_Ø§Ù„ÙˆØ¸ÙŠÙØ©   \n",
              "73  Fi_Al_Hadaraa  Ø§Ù„Ù„ØºØ©__ÙƒÙŠÙ_ÙÙ‚Ø¯Ù†Ø§_Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©_Ù„Ù„ØºØ©_Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©__ÙÙŠ_Ø§Ù„Ø­...   \n",
              "\n",
              "                                      Original Script Processed Script  \\\n",
              "94  ÙŠØ¹Ù†ÙŠ Ø®Ù„Ø§ØµØŸ\\nÙ…Ø§ ÙÙŠØ´ Ù…Ù†Ù‘Ù‡ ØªØ§Ù†ÙŠØŸ\\nÙ…Ø§ Ø®Ù„Ø§Øµ Ø¨Ù‚Ù‰ ÙŠØ§ ...                    \n",
              "85  Ø¯Ù„ÙˆÙ‚ØªÙŠ Ø§Ù„Ù…Ø¤Ø³Ø³Ø§Øª ÙˆØ§Ù„Ø´Ø±ÙƒØ§Øª Ø¨Ù‚Øª Ù…Ø®Ù„ÙŠÙ‡Ø§\\nÙ…Ø³Ø§Ù„Ù‡ ØªØ¯Ø±...                    \n",
              "73  ÙŠØ§ Ù†Ø¬Ù Ø¨Ù†Ù‘ÙˆØ±ØŒ ØµØ¯ÙŠÙ‚ÙŠ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†. ØµØ¯ÙŠÙ‚ÙŠ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†!\\nØ§...                    \n",
              "\n",
              "   Dialogue     Type    Length        Category  \n",
              "94           Youtube  00:24:18   Entertainment  \n",
              "85           Youtube  00:00:58  People & Blogs  \n",
              "73           Youtube  00:17:23  People & Blogs  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "ğŸ“Œ Sample rows from channel: Al_Mokhbir_Al_Eqtisadi\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>Episode Title</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Dialogue</th>\n",
              "      <th>Type</th>\n",
              "      <th>Length</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Al_Mokhbir_Al_Eqtisadi</td>\n",
              "      <td>Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ__ÙƒÙŠÙ_Ø®Ø·Ø·Øª_Ø£Ù…Ø±ÙŠÙƒØ§_Ø³Ø±Ø§_Ù„ØªØ¹Ù‚ÙŠÙ…_Ø³...</td>\n",
              "      <td>ÙÙŠ Ø£ÙˆØ§Ø¦Ù„ Ø§Ù„ØªØ³Ø¹ÙŠÙ†ÙŠØ§Øª Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù… ÙÙŠ Ø§Ù„Ø¨Ø±Ø§Ø²ÙŠÙ„\\nÙƒ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:14:21</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>Al_Mokhbir_Al_Eqtisadi</td>\n",
              "      <td>Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ__ÙƒÙŠÙ_Ø¯ÙØ¹_Ø±Ø¬Ù„_ÙˆØ§Ù…Ø±Ø£Ø©_Ø§Ù‚ØªØµØ§Ø¯_Ø¨Ø±...</td>\n",
              "      <td>Ø±Ø§Ø¬Ù„ ÙˆÙˆØ§Ø­Ø¯Ø© Ø³Øª\\nØ§Ù„Ø§ØªÙ†ÙŠÙ† Ø§Ù„Ù…Ø­ØªØ±Ù…ÙŠÙ† Ø¯ÙˆÙ„ Ø·Ù„Ø¹ÙˆØ§ ÙÙŠ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:21:00</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>Al_Mokhbir_Al_Eqtisadi</td>\n",
              "      <td>Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ__ÙƒÙŠÙ_Ø£ØµØ¨Ø­_Ø§Ù„Ù…ØºØ±Ø¨_Ø­Ø§Ø±Ø³_Ø¨ÙˆØ§Ø¨Ø©_Ø§...</td>\n",
              "      <td>Ø¹Ø§Ø±ÙÙŠÙ† Ù‡ÙˆÙ„Ù†Ø¯Ø§ØŸ\\nØ£ÙƒÙŠØ¯ Ø¹Ø§Ø±ÙÙŠÙ†Ù‡Ø§\\nÙˆØ£ÙƒÙŠØ¯ Ø¨Ø±Ø¶Ùˆ Ø³Ù…Ø¹Øª...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:14:30</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Channel  \\\n",
              "114  Al_Mokhbir_Al_Eqtisadi   \n",
              "175  Al_Mokhbir_Al_Eqtisadi   \n",
              "315  Al_Mokhbir_Al_Eqtisadi   \n",
              "\n",
              "                                         Episode Title  \\\n",
              "114  Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ__ÙƒÙŠÙ_Ø®Ø·Ø·Øª_Ø£Ù…Ø±ÙŠÙƒØ§_Ø³Ø±Ø§_Ù„ØªØ¹Ù‚ÙŠÙ…_Ø³...   \n",
              "175  Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ__ÙƒÙŠÙ_Ø¯ÙØ¹_Ø±Ø¬Ù„_ÙˆØ§Ù…Ø±Ø£Ø©_Ø§Ù‚ØªØµØ§Ø¯_Ø¨Ø±...   \n",
              "315  Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ__ÙƒÙŠÙ_Ø£ØµØ¨Ø­_Ø§Ù„Ù…ØºØ±Ø¨_Ø­Ø§Ø±Ø³_Ø¨ÙˆØ§Ø¨Ø©_Ø§...   \n",
              "\n",
              "                                       Original Script Processed Script  \\\n",
              "114  ÙÙŠ Ø£ÙˆØ§Ø¦Ù„ Ø§Ù„ØªØ³Ø¹ÙŠÙ†ÙŠØ§Øª Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù… ÙÙŠ Ø§Ù„Ø¨Ø±Ø§Ø²ÙŠÙ„\\nÙƒ...                    \n",
              "175  Ø±Ø§Ø¬Ù„ ÙˆÙˆØ§Ø­Ø¯Ø© Ø³Øª\\nØ§Ù„Ø§ØªÙ†ÙŠÙ† Ø§Ù„Ù…Ø­ØªØ±Ù…ÙŠÙ† Ø¯ÙˆÙ„ Ø·Ù„Ø¹ÙˆØ§ ÙÙŠ...                    \n",
              "315  Ø¹Ø§Ø±ÙÙŠÙ† Ù‡ÙˆÙ„Ù†Ø¯Ø§ØŸ\\nØ£ÙƒÙŠØ¯ Ø¹Ø§Ø±ÙÙŠÙ†Ù‡Ø§\\nÙˆØ£ÙƒÙŠØ¯ Ø¨Ø±Ø¶Ùˆ Ø³Ù…Ø¹Øª...                    \n",
              "\n",
              "    Dialogue     Type    Length       Category  \n",
              "114           Youtube  00:14:21  Entertainment  \n",
              "175           Youtube  00:21:00  Entertainment  \n",
              "315           Youtube  00:14:30  Entertainment  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def sample_rows_per_channel(df, channel_column=\"Channel\", num_samples=3):\n",
        "    unique_channels = df[channel_column].unique()\n",
        "    for channel in unique_channels:\n",
        "        print(f\"ğŸ“Œ Sample rows from channel: {channel}\")\n",
        "        display(df[df[channel_column] == channel].sample(min(num_samples, len(df[df[channel_column] == channel]))))\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "print(\"ğŸ“ Checking Unlabelled DataFrame:\")\n",
        "sample_rows_per_channel(unlabelled_df)\n",
        "\n",
        "print(\"\\nğŸ“ Checking Labelled DataFrame:\")\n",
        "sample_rows_per_channel(labelled_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analysis & Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Analysis on Original Script\n",
        "\t\n",
        "\tChannel Analysis:\n",
        "\t- avg length / duration of episodes per channel\n",
        "\t- modal categories per channel, Category / class imbalance\n",
        "\t- etc\n",
        "\t- metdata analysis\n",
        "\t- Text Charactertistics (formal / informal... dialogue?)\n",
        "\t\n",
        "\tNLP Analysis:\n",
        "\t- Text Sampling\n",
        "\t- Text Statistics (word count, sentence length...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk import tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def arabic_tokenizer(text):\n",
        "    return tokenize.word_tokenize(text)\n",
        "\n",
        "# Combine Arabic + English stopwords\n",
        "ALL_STOPWORDS = set(stopwords.words(\"arabic\") + stopwords.words(\"english\"))\n",
        "\n",
        "def analyze_channel_data(labelled_df):\n",
        "    print(\"=== CHANNEL ANALYSIS ===\")\n",
        "\n",
        "    df = labelled_df.copy()\n",
        "    df = df.dropna(subset=[\"Category\"])\n",
        "    df[\"Script Length\"] = df[\"Original Script\"].apply(lambda x: len(arabic_tokenizer(x)))\n",
        "\n",
        "    # Average Script length per channel\n",
        "    avg_length = df.groupby(\"Channel\")[\"Script Length\"].mean()\n",
        "    print(\"\\nğŸ“Œ Average Episode Length per Channel:\\n\", avg_length)\n",
        "\n",
        "    # Number of episodes per channel\n",
        "    episode_count = df.groupby(\"Channel\")[\"Episode Title\"].nunique()\n",
        "    print(\"\\nğŸ“Œ Number of Episodes per Channel:\\n\", episode_count)\n",
        "\n",
        "    # Most common category per channel\n",
        "    modal_category = df.groupby(\"Channel\")[\"Category\"].agg(lambda x: x.value_counts().idxmax() if x.value_counts().size > 0 else \"Unknown\")\n",
        "    print(\"\\nğŸ“Œ Most Common Category per Channel:\\n\", modal_category)\n",
        "\n",
        "    # Plot category distribution\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    category_distribution = df[\"Category\"].value_counts()\n",
        "    sns.barplot(x=category_distribution.index, y=category_distribution.values, palette=\"viridis\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.title(\"Category Distribution\")\n",
        "    plt.show()\n",
        "\n",
        "    # Dialogue analysis\n",
        "    if \"Dialogue\" in df.columns and df[\"Dialogue\"].notna().sum() > 0:\n",
        "        dialogue_counts = df[\"Dialogue\"].dropna().value_counts()\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.barplot(x=dialogue_counts.index, y=dialogue_counts.values, palette=\"coolwarm\")\n",
        "        plt.title(\"Dialogue vs. Non-Dialogue Distribution\")\n",
        "        plt.show()\n",
        "\n",
        "def analyze_nlp_statistics(labelled_df):\n",
        "    print(\"=== NLP ANALYSIS ===\")\n",
        "\n",
        "    df = labelled_df.copy()\n",
        "    df[\"Word Count\"] = df[\"Original Script\"].apply(lambda x: len(arabic_tokenizer(x)))\n",
        "    print(\"\\nğŸ“Œ Word Count Statistics:\\n\", df[\"Word Count\"].describe())\n",
        "\n",
        "    # Lexical diversity\n",
        "    all_words = [word.lower() for sentence in df[\"Original Script\"] for word in arabic_tokenizer(sentence)]\n",
        "    unique_words = set(all_words)\n",
        "    lexical_diversity = len(unique_words) / len(all_words) if all_words else 0\n",
        "    print(\"\\nğŸ“Œ Lexical Diversity:\", round(lexical_diversity, 4))\n",
        "\n",
        "    # Stopword ratio\n",
        "    filtered_words = [word for word in all_words if word not in ALL_STOPWORDS]\n",
        "    stopword_ratio = 1 - (len(filtered_words) / len(all_words)) if all_words else 0\n",
        "    print(\"\\nğŸ“Œ Percentage of Stopwords:\", round(stopword_ratio * 100, 2), \"%\")\n",
        "\n",
        "    # Most common words\n",
        "    common_words = Counter(filtered_words)\n",
        "    print(\"\\nğŸ“Œ Most Common Words:\\n\", common_words.most_common(10))\n",
        "\n",
        "    # Common bigrams and trigrams\n",
        "    bigrams = list(ngrams(filtered_words, 2))\n",
        "    trigrams = list(ngrams(filtered_words, 3))\n",
        "    print(\"\\nğŸ“Œ Most Common Bigrams:\\n\", Counter(bigrams).most_common(10))\n",
        "    print(\"\\nğŸ“Œ Most Common Trigrams:\\n\", Counter(trigrams).most_common(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Abbreviations Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Labelled Dataset ===\n",
            "\n",
            "ğŸ“Œ Channel: Al_Mokhbir_Al_Eqtisadi\n",
            "Total Unique Abbreviations: 91\n",
            "Abbreviations & Counts:\n",
            "CIA: 1 times\n",
            "USAID: 1 times\n",
            "FOMC: 5 times\n",
            "IOS: 1 times\n",
            "CFA: 22 times\n",
            "SDECE: 1 times\n",
            "GSM: 2 times\n",
            "ETLA: 2 times\n",
            "BASF: 1 times\n",
            "ISO: 3 times\n",
            "AEPR: 3 times\n",
            "AK: 1 times\n",
            "NNPC: 1 times\n",
            "DGB: 1 times\n",
            "AG: 3 times\n",
            "GMBH: 1 times\n",
            "FBI: 1 times\n",
            "IQ: 2 times\n",
            "FOMO: 1 times\n",
            "SE: 1 times\n",
            "SAMA: 1 times\n",
            "SDR: 3 times\n",
            "ARAMCO: 1 times\n",
            "LNG: 1 times\n",
            "BIS: 1 times\n",
            "NUDT: 1 times\n",
            "EDA: 4 times\n",
            "ASML: 61 times\n",
            "FDPR: 1 times\n",
            "SMIC: 2 times\n",
            "DRAM: 1 times\n",
            "NAND: 2 times\n",
            "CCD: 1 times\n",
            "MH: 1 times\n",
            "SES: 1 times\n",
            "MSNBC: 1 times\n",
            "ABS: 1 times\n",
            "CEF: 1 times\n",
            "AA: 1 times\n",
            "OPC: 10 times\n",
            "DUV: 6 times\n",
            "EUV: 13 times\n",
            "SK: 1 times\n",
            "CFIUS: 3 times\n",
            "DOI: 2 times\n",
            "GIC: 3 times\n",
            "ITRI: 1 times\n",
            "TSMC: 5 times\n",
            "CSET: 1 times\n",
            "API: 2 times\n",
            "KPMG: 1 times\n",
            "CII: 1 times\n",
            "BYD: 64 times\n",
            "PHEV: 1 times\n",
            "NA: 1 times\n",
            "NBER: 1 times\n",
            "FTX: 63 times\n",
            "US: 2 times\n",
            "BUSD: 1 times\n",
            "FTT: 21 times\n",
            "AIG: 1 times\n",
            "CRP: 2 times\n",
            "ATM: 1 times\n",
            "CNC: 1 times\n",
            "NDTV: 1 times\n",
            "ERM: 2 times\n",
            "YCC: 2 times\n",
            "ENN: 1 times\n",
            "YARA: 1 times\n",
            "ECO: 1 times\n",
            "SEC: 1 times\n",
            "CHIPS: 1 times\n",
            "CCIEE: 1 times\n",
            "WS: 1 times\n",
            "MD: 2 times\n",
            "FAA: 1 times\n",
            "EASA: 1 times\n",
            "CAAC: 1 times\n",
            "UTC: 1 times\n",
            "FACC: 1 times\n",
            "CFM: 1 times\n",
            "SA: 1 times\n",
            "AVIC: 1 times\n",
            "TFR: 1 times\n",
            "OCP: 8 times\n",
            "IATA: 1 times\n",
            "VTB: 1 times\n",
            "MOEX: 1 times\n",
            "PRF: 2 times\n",
            "ESSF: 2 times\n",
            "ISIF: 1 times\n",
            "\n",
            "ğŸ“Œ Channel: B Hodoo2\n",
            "Total Unique Abbreviations: 0\n",
            "Abbreviations & Counts:\n",
            "\n",
            "ğŸ“Œ Channel: Business Bel Araby\n",
            "Total Unique Abbreviations: 0\n",
            "Abbreviations & Counts:\n",
            "\n",
            "ğŸ“Œ Channel: Fi_Al_Hadaraa\n",
            "Total Unique Abbreviations: 5\n",
            "Abbreviations & Counts:\n",
            "BM: 3 times\n",
            "CV: 1 times\n",
            "CEO: 1 times\n",
            "GDB: 1 times\n",
            "ICD: 1 times\n",
            "\n",
            "ğŸ“Œ Channel: Kefaya Ba2a\n",
            "Total Unique Abbreviations: 0\n",
            "Abbreviations & Counts:\n",
            "\n",
            "=== Unlabelled Dataset ===\n",
            "\n",
            "ğŸ“Œ Channel: Da7ee7\n",
            "Total Unique Abbreviations: 84\n",
            "Abbreviations & Counts:\n",
            "DEFCON: 4 times\n",
            "AI: 15 times\n",
            "BMI: 1 times\n",
            "MUTV: 1 times\n",
            "CTRL: 8 times\n",
            "OCD: 1 times\n",
            "AK: 1 times\n",
            "GTA: 2 times\n",
            "IB: 3 times\n",
            "IR: 1 times\n",
            "MIT: 4 times\n",
            "PACS: 4 times\n",
            "USB: 3 times\n",
            "IOS: 1 times\n",
            "IKEA: 1 times\n",
            "PR: 3 times\n",
            "NASA: 1 times\n",
            "WWWF: 1 times\n",
            "TV: 2 times\n",
            "WWE: 1 times\n",
            "IQ: 6 times\n",
            "ASL: 1 times\n",
            "ISS: 1 times\n",
            "CQD: 1 times\n",
            "SOS: 1 times\n",
            "SS: 8 times\n",
            "SHUT: 2 times\n",
            "UP: 3 times\n",
            "WORKING: 1 times\n",
            "GPS: 1 times\n",
            "TSMC: 13 times\n",
            "AMD: 1 times\n",
            "ASML: 6 times\n",
            "HOAX: 1 times\n",
            "FMRI: 1 times\n",
            "CCC: 2 times\n",
            "PDP: 1 times\n",
            "OS: 7 times\n",
            "MGM: 1 times\n",
            "CBS: 1 times\n",
            "MK: 3 times\n",
            "DC: 20 times\n",
            "BYD: 3 times\n",
            "POW: 1 times\n",
            "XX: 3 times\n",
            "XY: 2 times\n",
            "MBC: 1 times\n",
            "IV: 1 times\n",
            "LEED: 1 times\n",
            "DJ: 2 times\n",
            "SVP: 1 times\n",
            "ETF: 2 times\n",
            "IPO: 1 times\n",
            "NYU: 2 times\n",
            "DNA: 2 times\n",
            "ABC: 1 times\n",
            "ATP: 6 times\n",
            "CD: 1 times\n",
            "NOAA: 1 times\n",
            "ADHD: 1 times\n",
            "CDC: 1 times\n",
            "LSD: 3 times\n",
            "AWM: 1 times\n",
            "CV: 4 times\n",
            "HR: 6 times\n",
            "XIV: 1 times\n",
            "USA: 3 times\n",
            "CIA: 1 times\n",
            "STAR: 1 times\n",
            "DFD: 1 times\n",
            "PSE: 1 times\n",
            "FBI: 1 times\n",
            "BI: 1 times\n",
            "AA: 1 times\n",
            "JIT: 1 times\n",
            "BMW: 1 times\n",
            "GM: 1 times\n",
            "IMDB: 1 times\n",
            "PG: 1 times\n",
            "FM: 3 times\n",
            "PGMOL: 1 times\n",
            "PES: 1 times\n",
            "KFC: 1 times\n",
            "JBS: 1 times\n",
            "\n",
            "ğŸ“Œ Channel: Elsaha\n",
            "Total Unique Abbreviations: 0\n",
            "Abbreviations & Counts:\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def extract_abbreviations_per_channel(df, text_column=\"Original Script\", channel_column=\"Channel\"):\n",
        "    # Match words with only capital letters, min length 2\n",
        "    abbreviation_pattern = re.compile(r\"\\b[A-Z]{2,}\\b\")\n",
        "    \n",
        "    channel_abbreviation_stats = {}\n",
        "\n",
        "    for channel, group in df.groupby(channel_column):\n",
        "        all_abbreviations = []\n",
        "        \n",
        "        for text in group[text_column].dropna():\n",
        "            abbreviations = abbreviation_pattern.findall(text)\n",
        "            all_abbreviations.extend(abbreviations)\n",
        "        \n",
        "        abbreviation_counts = Counter(all_abbreviations)\n",
        "        channel_abbreviation_stats[channel] = abbreviation_counts\n",
        "    \n",
        "    return channel_abbreviation_stats\n",
        "\n",
        "# Run on both labelled and unlabelled datasets\n",
        "print(\"=== Labelled Dataset ===\")\n",
        "labelled_abbreviations = extract_abbreviations_per_channel(labelled_df)\n",
        "for channel, counts in labelled_abbreviations.items():\n",
        "    print(f\"\\nğŸ“Œ Channel: {channel}\")\n",
        "    print(f\"Total Unique Abbreviations: {len(counts)}\")\n",
        "    print(\"Abbreviations & Counts:\")\n",
        "    for abbr, count in counts.items():\n",
        "        print(f\"{abbr}: {count} times\")\n",
        "\n",
        "print(\"\\n=== Unlabelled Dataset ===\")\n",
        "unlabelled_abbreviations = extract_abbreviations_per_channel(unlabelled_df)\n",
        "for channel, counts in unlabelled_abbreviations.items():\n",
        "    print(f\"\\nğŸ“Œ Channel: {channel}\")\n",
        "    print(f\"Total Unique Abbreviations: {len(counts)}\")\n",
        "    print(\"Abbreviations & Counts:\")\n",
        "    for abbr, count in counts.items():\n",
        "        print(f\"{abbr}: {count} times\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Preprocessing\n",
        "\t- Punctuation, Symbols, Numbers, Diactritics (tashkeel) removal\n",
        "\t- Stemming / lemmatization?\n",
        "\t- Normalization of Arabic letters\n",
        "\t- Code switching handling? Translation? What about abbreviations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Arabic normalization map\n",
        "ARABIC_NORMALIZATION_MAP = str.maketrans({\n",
        "    \"Ø£\": \"Ø§\",\n",
        "    \"Ø¥\": \"Ø§\",\n",
        "    \"Ø¢\": \"Ø§\",\n",
        "    \"Ù‰\": \"ÙŠ\",\n",
        "    \"Ø©\": \"Ù‡\",\n",
        "})\n",
        "\n",
        "# Arabic punctuation characters\n",
        "ARABIC_PUNCTUATION = \"ØŸØŒØ›Â«Â»Ù€â€¦â€œâ€â€˜â€™â€“â€”\"\n",
        "\n",
        "# Combined punctuation\n",
        "ALL_PUNCTUATION = string.punctuation + ARABIC_PUNCTUATION\n",
        "\n",
        "# Arabic Stopword list (can be extended)\n",
        "ARABIC_STOPWORDS = set([\n",
        "    \"ÙÙŠ\", \"Ù…Ù†\", \"Ø¹Ù„Ù‰\", \"Ù…Ø§\", \"Ùˆ\", \"Ù„Ø§\", \"Ø¹Ù†\", \"Ø¥Ù„Ù‰\", \"Ø£Ù†\", \"Ù‡Ùˆ\", \"Ù‡ÙŠ\", \"Ù‡Ø°Ø§\", \"Ø°Ù„Ùƒ\", \"ÙƒÙ„\", \"ÙƒØ§Ù†\", \"ÙƒÙ…Ø§\",\n",
        "    \"Ù„Ø°Ù„Ùƒ\", \"Ø£Ùˆ\", \"Ø£ÙŠ\", \"Ù„Ù…\", \"Ù‚Ø¯\", \"Ø£ÙƒØ«Ø±\", \"Ø£Ù‚Ù„\", \"Ù‡Ù†Ø§\", \"Ù‡Ù†Ø§Ùƒ\", \"Ø¨Ø¹Ø¯\", \"Ù‚Ø¨Ù„\", \"Ø¨ÙŠÙ†\", \"Ù…Ø¹\", \"Ø­ØªÙ‰\", \"Ø¥Ø°Ø§\",\n",
        "    \"Ø«Ù…\", \"Ù„ÙƒÙ†\", \"Ø£Ø­Ø¯\", \"Ø£ÙŠØ¶Ø§\", \"Ø£Ø«Ù†Ø§Ø¡\", \"Ø¹Ù†Ø¯\", \"Ø£ÙŠÙ†\", \"ÙƒÙŠÙ\", \"Ø¥Ù„Ø§\", \"Ø£ØµØ¨Ø­\", \"Ù„Ø£Ù†\", \"Ø¨Ø³Ø¨Ø¨\", \"Ù‡Ø°Ù‡\", \"Ù‡Ø¤Ù„Ø§Ø¡\",\n",
        "    \"Ø§Ù„ØªÙŠ\", \"Ø§Ù„Ø°ÙŠ\", \"Ø§Ù„Ø°ÙŠÙ†\", \"Ø§Ù„Ù„Ø°ÙŠ\", \"Ø§Ù„Ù„Ø°ÙŠÙ†\", \"Ø§Ù„Ù„Ø§Ø¦ÙŠ\"\n",
        "])\n",
        "\n",
        "# English abbreviations dictionary\n",
        "ENGLISH_ABBREVIATIONS = {\n",
        "    \"CIA\": \"ÙˆÙƒØ§Ù„Ø© Ø§Ù„Ù…Ø®Ø§Ø¨Ø±Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©\",\n",
        "    \"USAID\": \"Ø§Ù„ÙˆÙƒØ§Ù„Ø© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ© Ù„Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©\",\n",
        "    \"FOMC\": \"Ø§Ù„Ù„Ø¬Ù†Ø© Ø§Ù„ÙÙŠØ¯Ø±Ø§Ù„ÙŠØ© Ù„Ù„Ø³ÙˆÙ‚ Ø§Ù„Ù…ÙØªÙˆØ­Ø©\",\n",
        "    \"IOS\": \"Ù†Ø¸Ø§Ù… ØªØ´ØºÙŠÙ„ Ø¢ÙŠ Ø£Ùˆ Ø¥Ø³\",\n",
        "    \"CFA\": \"Ù…Ø­Ù„Ù„ Ù…Ø§Ù„ÙŠ Ù…Ø¹ØªÙ…Ø¯\",\n",
        "    \"SDECE\": \"Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø³Ø±ÙŠØ© Ù„Ù„Ø¯ÙØ§Ø¹ Ø§Ù„ÙˆØ·Ù†ÙŠ\",\n",
        "    \"GSM\": \"Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ù„Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ù…ØªÙ†Ù‚Ù„Ø©\",\n",
        "    \"ETLA\": \"Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠ Ù„Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ…\",\n",
        "    \"BASF\": \"Ø´Ø±ÙƒØ© Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ©\",\n",
        "    \"ISO\": \"Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ù„Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ\",\n",
        "    \"AEPR\": \"Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø³Ù†ÙˆÙŠ Ù„Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ\",\n",
        "    \"AK\": \"ÙƒÙ„Ø§Ø´ÙŠÙ†ÙƒÙˆÙ\",\n",
        "    \"NNPC\": \"Ø´Ø±ÙƒØ© Ø§Ù„Ø¨ØªØ±ÙˆÙ„ Ø§Ù„ÙˆØ·Ù†ÙŠØ© Ø§Ù„Ù†ÙŠØ¬ÙŠØ±ÙŠØ©\",\n",
        "    \"DGB\": \"Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø£Ù…Ù†\",\n",
        "    \"AG\": \"Ø´Ø±ÙƒØ© Ø°Ø§Øª Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©\",\n",
        "    \"GMBH\": \"Ø´Ø±ÙƒØ© Ù…Ø­Ø¯ÙˆØ¯Ø© Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© ÙÙŠ Ø£Ù„Ù…Ø§Ù†ÙŠØ§\",\n",
        "    \"FBI\": \"Ù…ÙƒØªØ¨ Ø§Ù„ØªØ­Ù‚ÙŠÙ‚Ø§Øª Ø§Ù„ÙÙŠØ¯Ø±Ø§Ù„ÙŠ\",\n",
        "    \"IQ\": \"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡\",\n",
        "    \"FOMO\": \"Ø§Ù„Ø®ÙˆÙ Ù…Ù† ØªÙÙˆÙŠØª Ø§Ù„ÙØ±ØµØ©\",\n",
        "    \"SE\": \"Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ§Øª\",\n",
        "    \"SAMA\": \"Ù…Ø¤Ø³Ø³Ø© Ø§Ù„Ù†Ù‚Ø¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ\",\n",
        "    \"SDR\": \"Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„Ø®Ø§ØµØ©\",\n",
        "    \"ARAMCO\": \"Ø´Ø±ÙƒØ© Ø£Ø±Ø§Ù…ÙƒÙˆ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©\",\n",
        "    \"LNG\": \"Ø§Ù„ØºØ§Ø² Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ Ø§Ù„Ù…Ø³Ø§Ù„\",\n",
        "    \"BIS\": \"Ø¨Ù†Ùƒ Ø§Ù„ØªØ³ÙˆÙŠØ§Øª Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©\",\n",
        "    \"NUDT\": \"Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§\",\n",
        "    \"EDA\": \"Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©\",\n",
        "    \"ASML\": \"Ø´Ø±ÙƒØ© ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø£Ø´Ø¨Ø§Ù‡ Ø§Ù„Ù…ÙˆØµÙ„Ø§Øª\",\n",
        "    \"FDPR\": \"Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©\",\n",
        "    \"SMIC\": \"Ø´Ø±ÙƒØ© ØªØµÙ†ÙŠØ¹ Ø£Ø´Ø¨Ø§Ù‡ Ø§Ù„Ù…ÙˆØµÙ„Ø§Øª Ø§Ù„ØµÙŠÙ†ÙŠØ©\",\n",
        "    \"DRAM\": \"Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©\",\n",
        "    \"NAND\": \"Ø°Ø§ÙƒØ±Ø© ÙÙ„Ø§Ø´ Ù†Ø§Ù†Ø¯\",\n",
        "    \"CCD\": \"Ø¬Ù‡Ø§Ø² Ø§Ù„Ø´Ø­Ù† Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬\",\n",
        "    \"MH\": \"Ù…ÙŠØºØ§Ù‡ÙŠØ±ØªØ²\",\n",
        "    \"SES\": \"Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„ÙØ¶Ø§Ø¦ÙŠØ©\",\n",
        "    \"MSNBC\": \"Ù‚Ù†Ø§Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©\",\n",
        "    \"ABS\": \"Ù†Ø¸Ø§Ù… Ø§Ù„ÙØ±Ø§Ù…Ù„ Ø§Ù„Ù…Ø§Ù†Ø¹ Ù„Ù„Ø§Ù†ØºÙ„Ø§Ù‚\",\n",
        "    \"CEF\": \"ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„ØµØ±Ù Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠ\",\n",
        "    \"AA\": \"Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø¬ÙˆÙŠØ© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©\",\n",
        "    \"OPC\": \"Ù„Ø¬Ù†Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª\",\n",
        "    \"DUV\": \"Ø§Ù„Ø£Ø´Ø¹Ø© ÙÙˆÙ‚ Ø§Ù„Ø¨Ù†ÙØ³Ø¬ÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø©\",\n",
        "    \"EUV\": \"Ø§Ù„Ø£Ø´Ø¹Ø© ÙÙˆÙ‚ Ø§Ù„Ø¨Ù†ÙØ³Ø¬ÙŠØ© Ø§Ù„Ø´Ø¯ÙŠØ¯Ø©\",\n",
        "    \"CFIUS\": \"Ù„Ø¬Ù†Ø© Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠ ÙÙŠ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©\",\n",
        "    \"DOI\": \"ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©\",\n",
        "    \"GIC\": \"Ø´Ø±ÙƒØ© Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ©\",\n",
        "    \"ITRI\": \"Ù…Ø¹Ù‡Ø¯ Ø§Ù„Ø£Ø¨Ø­Ø§Ø« Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ©\",\n",
        "    \"TSMC\": \"Ø´Ø±ÙƒØ© ØªØµÙ†ÙŠØ¹ Ø£Ø´Ø¨Ø§Ù‡ Ø§Ù„Ù…ÙˆØµÙ„Ø§Øª Ø§Ù„ØªØ§ÙŠÙˆØ§Ù†ÙŠØ©\",\n",
        "    \"API\": \"ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª\",\n",
        "    \"KPMG\": \"Ø´Ø±ÙƒØ© Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©\",\n",
        "    \"CII\": \"Ø§ØªØ­Ø§Ø¯ Ø§Ù„ØµÙ†Ø§Ø¹Ø§Øª Ø§Ù„Ù‡Ù†Ø¯ÙŠØ©\",\n",
        "    \"BYD\": \"Ø´Ø±ÙƒØ© Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙŠÙ†ÙŠØ©\",\n",
        "    \"PHEV\": \"Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø§Ù„Ù‡Ø¬ÙŠÙ†Ø©\",\n",
        "    \"NBER\": \"Ø§Ù„Ù…ÙƒØªØ¨ Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„Ø¨Ø­ÙˆØ« Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©\",\n",
        "    \"FTX\": \"Ù…Ù†ØµØ© ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\",\n",
        "    \"US\": \"Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©\",\n",
        "    \"BUSD\": \"Ø¹Ù…Ù„Ø© Ø¨ÙŠÙ†Ø§Ù†Ø³ Ø§Ù„Ù…Ø³ØªÙ‚Ø±Ø©\",\n",
        "    \"FTT\": \"Ø±Ù…Ø² FTX Ø§Ù„Ø£ØµÙ„ÙŠ\",\n",
        "    \"AIG\": \"Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ£Ù…ÙŠÙ† Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©\",\n",
        "    \"CRP\": \"Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠ\",\n",
        "    \"ATM\": \"Ø§Ù„ØµØ±Ø§Ù Ø§Ù„Ø¢Ù„ÙŠ\",\n",
        "    \"CNC\": \"Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø¨Ø§Ù„ÙƒÙ…Ø¨ÙŠÙˆØªØ±\",\n",
        "    \"NDTV\": \"Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ù‡Ù†Ø¯ÙŠØ© Ø§Ù„Ø¥Ø®Ø¨Ø§Ø±ÙŠØ©\",\n",
        "    \"ERM\": \"Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ©\",\n",
        "    \"YCC\": \"Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¹Ø§Ø¦Ø¯\",\n",
        "    \"ENN\": \"Ø´Ø±ÙƒØ© Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„ØµÙŠÙ†ÙŠØ©\",\n",
        "    \"ECO\": \"Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨ÙŠØ¦ÙŠ\",\n",
        "    \"SEC\": \"Ù„Ø¬Ù†Ø© Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ù…Ø§Ù„ÙŠØ© ÙˆØ§Ù„Ø¨ÙˆØ±ØµØ§Øª\",\n",
        "    \"CHIPS\": \"Ù‚Ø§Ù†ÙˆÙ† Ø¯Ø¹Ù… Ø¥Ù†ØªØ§Ø¬ Ø£Ø´Ø¨Ø§Ù‡ Ø§Ù„Ù…ÙˆØµÙ„Ø§Øª\",\n",
        "    \"CCIEE\": \"Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„ØµÙŠÙ†ÙŠ Ù„Ù„ØªØ¨Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©\",\n",
        "    \"WS\": \"ÙˆÙˆÙ„ Ø³ØªØ±ÙŠØª\",\n",
        "    \"MD\": \"Ø§Ù„Ù…Ø¯ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠ\",\n",
        "    \"FAA\": \"Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø·ÙŠØ±Ø§Ù† Ø§Ù„ÙÙŠØ¯Ø±Ø§Ù„ÙŠØ©\",\n",
        "    \"IATA\": \"Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ù„Ù„Ù†Ù‚Ù„ Ø§Ù„Ø¬ÙˆÙŠ\",\n",
        "    \"MIT\": \"Ù…Ø¹Ù‡Ø¯ Ù…Ø§Ø³Ø§ØªØ´ÙˆØ³ØªØ³ Ù„Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§\",\n",
        "    \"PACS\": \"Ù†Ø¸Ø§Ù… Ø£Ø±Ø´ÙØ© Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ø§ØªØµØ§Ù„Ø§Øª\",\n",
        "    \"USB\": \"Ù…Ù†ÙØ° Ø§Ù„Ù†Ø§Ù‚Ù„ Ø§Ù„ØªØ³Ù„Ø³Ù„ÙŠ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ\",\n",
        "    \"NASA\": \"ÙˆÙƒØ§Ù„Ø© Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©\",\n",
        "    \"WWE\": \"Ø§Ù„Ù…ØµØ§Ø±Ø¹Ø© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ø§Ù„ØªØ±ÙÙŠÙ‡ÙŠØ©\",\n",
        "    \"GPS\": \"Ù†Ø¸Ø§Ù… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ\"\n",
        "}\n",
        "\n",
        "import qalsadi.lemmatizer\n",
        "import pyarabic.araby as araby\n",
        "\n",
        "# Initialize Qalsadi lemmatizer\n",
        "lemmatizer = qalsadi.lemmatizer.Lemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return \"\"\n",
        "\n",
        "    # Replace newline characters with space\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    # Normalize Arabic letters\n",
        "    text = text.translate(ARABIC_NORMALIZATION_MAP)\n",
        "\n",
        "    # Replace English abbreviations\n",
        "    words = text.split()\n",
        "    replaced_words = []\n",
        "    for word in words:\n",
        "        if re.match(r\"^[A-Z]{2,}$\", word):\n",
        "            word = ENGLISH_ABBREVIATIONS.get(word.upper(), word)\n",
        "        replaced_words.append(word)\n",
        "    text = \" \".join(replaced_words)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = re.sub(f\"[{re.escape(ALL_PUNCTUATION)}]\", \" \", text)\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    filtered_tokens = [tok for tok in tokens if tok not in ARABIC_STOPWORDS]\n",
        "\n",
        "    # Apply lemmatization using Qalsadi\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(tok) for tok in filtered_tokens]\n",
        "\n",
        "    return \" \".join(lemmatized_tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "for df in [unlabelled_df, labelled_df]:\n",
        "    df[\"Processed Script\"] = df[\"Original Script\"].apply(preprocess_text)\n",
        "\n",
        "print(\"âœ… Preprocessing completed (NLTK tokenization, stopwords, punctuation, newline handled).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/sherifahammoud/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/sherifahammoud/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Preprocessing completed (NLTK tokenization, stopwords, punctuation, newline handled).\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "ARABIC_NORMALIZATION_MAP = str.maketrans({\n",
        "    \"Ø£\": \"Ø§\",\n",
        "    \"Ø¥\": \"Ø§\",\n",
        "    \"Ø¢\": \"Ø§\",\n",
        "    \"Ù‰\": \"ÙŠ\",\n",
        "    \"Ø©\": \"Ù‡\",\n",
        "})\n",
        "\n",
        "ARABIC_PUNCTUATION = \"ØŸØŒØ›Â«Â»Ù€â€¦â€œâ€â€˜â€™â€“â€”\"\n",
        "\n",
        "ALL_PUNCTUATION = string.punctuation + ARABIC_PUNCTUATION\n",
        "\n",
        "ARABIC_STOPWORDS = set([\n",
        "    \"ÙÙŠ\", \"Ù…Ù†\", \"Ø¹Ù„Ù‰\", \"Ù…Ø§\", \"Ùˆ\", \"Ù„Ø§\", \"Ø¹Ù†\", \"Ø¥Ù„Ù‰\", \"Ø£Ù†\", \"Ù‡Ùˆ\", \"Ù‡ÙŠ\", \"Ù‡Ø°Ø§\", \"Ø°Ù„Ùƒ\", \"ÙƒÙ„\", \"ÙƒØ§Ù†\", \"ÙƒÙ…Ø§\",\n",
        "    \"Ù„Ø°Ù„Ùƒ\", \"Ø£Ùˆ\", \"Ø£ÙŠ\", \"Ù„Ù…\", \"Ù‚Ø¯\", \"Ø£ÙƒØ«Ø±\", \"Ø£Ù‚Ù„\", \"Ù‡Ù†Ø§\", \"Ù‡Ù†Ø§Ùƒ\", \"Ø¨Ø¹Ø¯\", \"Ù‚Ø¨Ù„\", \"Ø¨ÙŠÙ†\", \"Ù…Ø¹\", \"Ø­ØªÙ‰\", \"Ø¥Ø°Ø§\",\n",
        "    \"Ø«Ù…\", \"Ù„ÙƒÙ†\", \"Ø£Ø­Ø¯\", \"Ø£ÙŠØ¶Ø§\", \"Ø£Ø«Ù†Ø§Ø¡\", \"Ø¹Ù†Ø¯\", \"Ø£ÙŠÙ†\", \"ÙƒÙŠÙ\", \"Ø¥Ù„Ø§\", \"Ø£ØµØ¨Ø­\", \"Ù„Ø£Ù†\", \"Ø¨Ø³Ø¨Ø¨\", \"Ù‡Ø°Ù‡\", \"Ù‡Ø¤Ù„Ø§Ø¡\",\n",
        "    \"Ø§Ù„ØªÙŠ\", \"Ø§Ù„Ø°ÙŠ\", \"Ø§Ù„Ø°ÙŠÙ†\", \"Ø§Ù„Ù„Ø°ÙŠ\", \"Ø§Ù„Ù„Ø°ÙŠÙ†\", \"Ø§Ù„Ù„Ø§Ø¦ÙŠ\"\n",
        "])\n",
        "\n",
        "ENGLISH_ABBREVIATIONS = {\n",
        "    \"CIA\": \"ÙˆÙƒØ§Ù„Ø© Ø§Ù„Ù…Ø®Ø§Ø¨Ø±Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©\",\n",
        "    \"USAID\": \"Ø§Ù„ÙˆÙƒØ§Ù„Ø© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ© Ù„Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©\",\n",
        "    \"FOMC\": \"Ø§Ù„Ù„Ø¬Ù†Ø© Ø§Ù„ÙÙŠØ¯Ø±Ø§Ù„ÙŠØ© Ù„Ù„Ø³ÙˆÙ‚ Ø§Ù„Ù…ÙØªÙˆØ­Ø©\",\n",
        "    \"IOS\": \"Ù†Ø¸Ø§Ù… ØªØ´ØºÙŠÙ„ Ø¢ÙŠ Ø£Ùˆ Ø¥Ø³\",\n",
        "    \"CFA\": \"Ù…Ø­Ù„Ù„ Ù…Ø§Ù„ÙŠ Ù…Ø¹ØªÙ…Ø¯\",\n",
        "    \"SDECE\": \"Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø³Ø±ÙŠØ© Ù„Ù„Ø¯ÙØ§Ø¹ Ø§Ù„ÙˆØ·Ù†ÙŠ\",\n",
        "    \"GSM\": \"Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ù„Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ù…ØªÙ†Ù‚Ù„Ø©\",\n",
        "    \"ETLA\": \"Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠ Ù„Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ…\",\n",
        "    \"BASF\": \"Ø´Ø±ÙƒØ© Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ©\",\n",
        "    \"ISO\": \"Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ù„Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ\",\n",
        "    \"AEPR\": \"Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø³Ù†ÙˆÙŠ Ù„Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ\",\n",
        "    \"AK\": \"ÙƒÙ„Ø§Ø´ÙŠÙ†ÙƒÙˆÙ\",\n",
        "    \"NNPC\": \"Ø´Ø±ÙƒØ© Ø§Ù„Ø¨ØªØ±ÙˆÙ„ Ø§Ù„ÙˆØ·Ù†ÙŠØ© Ø§Ù„Ù†ÙŠØ¬ÙŠØ±ÙŠØ©\",\n",
        "    \"DGB\": \"Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø£Ù…Ù†\",\n",
        "    \"AG\": \"Ø´Ø±ÙƒØ© Ø°Ø§Øª Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©\",\n",
        "    \"GMBH\": \"Ø´Ø±ÙƒØ© Ù…Ø­Ø¯ÙˆØ¯Ø© Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© ÙÙŠ Ø£Ù„Ù…Ø§Ù†ÙŠØ§\",\n",
        "    \"FBI\": \"Ù…ÙƒØªØ¨ Ø§Ù„ØªØ­Ù‚ÙŠÙ‚Ø§Øª Ø§Ù„ÙÙŠØ¯Ø±Ø§Ù„ÙŠ\",\n",
        "    \"IQ\": \"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡\",\n",
        "    \"FOMO\": \"Ø§Ù„Ø®ÙˆÙ Ù…Ù† ØªÙÙˆÙŠØª Ø§Ù„ÙØ±ØµØ©\",\n",
        "    \"SE\": \"Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ§Øª\",\n",
        "    \"SAMA\": \"Ù…Ø¤Ø³Ø³Ø© Ø§Ù„Ù†Ù‚Ø¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ\",\n",
        "    \"SDR\": \"Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„Ø®Ø§ØµØ©\",\n",
        "    \"ARAMCO\": \"Ø´Ø±ÙƒØ© Ø£Ø±Ø§Ù…ÙƒÙˆ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©\",\n",
        "    \"LNG\": \"Ø§Ù„ØºØ§Ø² Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ Ø§Ù„Ù…Ø³Ø§Ù„\",\n",
        "    \"BIS\": \"Ø¨Ù†Ùƒ Ø§Ù„ØªØ³ÙˆÙŠØ§Øª Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©\",\n",
        "    \"NUDT\": \"Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§\",\n",
        "    \"EDA\": \"Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©\",\n",
        "    \"ASML\": \"Ø´Ø±ÙƒØ© ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø£Ø´Ø¨Ø§Ù‡ Ø§Ù„Ù…ÙˆØµÙ„Ø§Øª\",\n",
        "    \"FDPR\": \"Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©\",\n",
        "    \"SMIC\": \"Ø´Ø±ÙƒØ© ØªØµÙ†ÙŠØ¹ Ø£Ø´Ø¨Ø§Ù‡ Ø§Ù„Ù…ÙˆØµÙ„Ø§Øª Ø§Ù„ØµÙŠÙ†ÙŠØ©\",\n",
        "    \"DRAM\": \"Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©\",\n",
        "    \"NAND\": \"Ø°Ø§ÙƒØ±Ø© ÙÙ„Ø§Ø´ Ù†Ø§Ù†Ø¯\",\n",
        "    \"CCD\": \"Ø¬Ù‡Ø§Ø² Ø§Ù„Ø´Ø­Ù† Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬\",\n",
        "    \"MH\": \"Ù…ÙŠØºØ§Ù‡ÙŠØ±ØªØ²\",\n",
        "    \"SES\": \"Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„ÙØ¶Ø§Ø¦ÙŠØ©\",\n",
        "    \"MSNBC\": \"Ù‚Ù†Ø§Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©\",\n",
        "    \"ABS\": \"Ù†Ø¸Ø§Ù… Ø§Ù„ÙØ±Ø§Ù…Ù„ Ø§Ù„Ù…Ø§Ù†Ø¹ Ù„Ù„Ø§Ù†ØºÙ„Ø§Ù‚\",\n",
        "    \"CEF\": \"ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„ØµØ±Ù Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠ\",\n",
        "    \"AA\": \"Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø¬ÙˆÙŠØ© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©\",\n",
        "    \"OPC\": \"Ù„Ø¬Ù†Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª\",\n",
        "    \"DUV\": \"Ø§Ù„Ø£Ø´Ø¹Ø© ÙÙˆÙ‚ Ø§Ù„Ø¨Ù†ÙØ³Ø¬ÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø©\",\n",
        "    \"EUV\": \"Ø§Ù„Ø£Ø´Ø¹Ø© ÙÙˆÙ‚ Ø§Ù„Ø¨Ù†ÙØ³Ø¬ÙŠØ© Ø§Ù„Ø´Ø¯ÙŠØ¯Ø©\",\n",
        "    \"CFIUS\": \"Ù„Ø¬Ù†Ø© Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠ ÙÙŠ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©\",\n",
        "    \"DOI\": \"ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©\",\n",
        "    \"GIC\": \"Ø´Ø±ÙƒØ© Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ©\",\n",
        "    \"ITRI\": \"Ù…Ø¹Ù‡Ø¯ Ø§Ù„Ø£Ø¨Ø­Ø§Ø« Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ©\",\n",
        "    \"TSMC\": \"Ø´Ø±ÙƒØ© ØªØµÙ†ÙŠØ¹ Ø£Ø´Ø¨Ø§Ù‡ Ø§Ù„Ù…ÙˆØµÙ„Ø§Øª Ø§Ù„ØªØ§ÙŠÙˆØ§Ù†ÙŠØ©\",\n",
        "    \"API\": \"ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª\",\n",
        "    \"KPMG\": \"Ø´Ø±ÙƒØ© Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©\",\n",
        "    \"CII\": \"Ø§ØªØ­Ø§Ø¯ Ø§Ù„ØµÙ†Ø§Ø¹Ø§Øª Ø§Ù„Ù‡Ù†Ø¯ÙŠØ©\",\n",
        "    \"BYD\": \"Ø´Ø±ÙƒØ© Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙŠÙ†ÙŠØ©\",\n",
        "    \"PHEV\": \"Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø§Ù„Ù‡Ø¬ÙŠÙ†Ø©\",\n",
        "    \"NBER\": \"Ø§Ù„Ù…ÙƒØªØ¨ Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„Ø¨Ø­ÙˆØ« Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©\",\n",
        "    \"FTX\": \"Ù…Ù†ØµØ© ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\",\n",
        "    \"US\": \"Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©\",\n",
        "    \"BUSD\": \"Ø¹Ù…Ù„Ø© Ø¨ÙŠÙ†Ø§Ù†Ø³ Ø§Ù„Ù…Ø³ØªÙ‚Ø±Ø©\",\n",
        "    \"FTT\": \"Ø±Ù…Ø² FTX Ø§Ù„Ø£ØµÙ„ÙŠ\",\n",
        "    \"AIG\": \"Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ£Ù…ÙŠÙ† Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©\",\n",
        "    \"CRP\": \"Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠ\",\n",
        "    \"ATM\": \"Ø§Ù„ØµØ±Ø§Ù Ø§Ù„Ø¢Ù„ÙŠ\",\n",
        "    \"CNC\": \"Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø¨Ø§Ù„ÙƒÙ…Ø¨ÙŠÙˆØªØ±\",\n",
        "    \"NDTV\": \"Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ù‡Ù†Ø¯ÙŠØ© Ø§Ù„Ø¥Ø®Ø¨Ø§Ø±ÙŠØ©\",\n",
        "    \"ERM\": \"Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ©\",\n",
        "    \"YCC\": \"Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¹Ø§Ø¦Ø¯\",\n",
        "    \"ENN\": \"Ø´Ø±ÙƒØ© Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„ØµÙŠÙ†ÙŠØ©\",\n",
        "    \"ECO\": \"Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨ÙŠØ¦ÙŠ\",\n",
        "    \"SEC\": \"Ù„Ø¬Ù†Ø© Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ù…Ø§Ù„ÙŠØ© ÙˆØ§Ù„Ø¨ÙˆØ±ØµØ§Øª\",\n",
        "    \"CHIPS\": \"Ù‚Ø§Ù†ÙˆÙ† Ø¯Ø¹Ù… Ø¥Ù†ØªØ§Ø¬ Ø£Ø´Ø¨Ø§Ù‡ Ø§Ù„Ù…ÙˆØµÙ„Ø§Øª\",\n",
        "    \"CCIEE\": \"Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„ØµÙŠÙ†ÙŠ Ù„Ù„ØªØ¨Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©\",\n",
        "    \"WS\": \"ÙˆÙˆÙ„ Ø³ØªØ±ÙŠØª\",\n",
        "    \"MD\": \"Ø§Ù„Ù…Ø¯ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠ\",\n",
        "    \"FAA\": \"Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø·ÙŠØ±Ø§Ù† Ø§Ù„ÙÙŠØ¯Ø±Ø§Ù„ÙŠØ©\",\n",
        "    \"IATA\": \"Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ù„Ù„Ù†Ù‚Ù„ Ø§Ù„Ø¬ÙˆÙŠ\",\n",
        "    \"MIT\": \"Ù…Ø¹Ù‡Ø¯ Ù…Ø§Ø³Ø§ØªØ´ÙˆØ³ØªØ³ Ù„Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§\",\n",
        "    \"PACS\": \"Ù†Ø¸Ø§Ù… Ø£Ø±Ø´ÙØ© Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ø§ØªØµØ§Ù„Ø§Øª\",\n",
        "    \"USB\": \"Ù…Ù†ÙØ° Ø§Ù„Ù†Ø§Ù‚Ù„ Ø§Ù„ØªØ³Ù„Ø³Ù„ÙŠ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ\",\n",
        "    \"NASA\": \"ÙˆÙƒØ§Ù„Ø© Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©\",\n",
        "    \"WWE\": \"Ø§Ù„Ù…ØµØ§Ø±Ø¹Ø© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ø§Ù„ØªØ±ÙÙŠÙ‡ÙŠØ©\",\n",
        "    \"GPS\": \"Ù†Ø¸Ø§Ù… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ\"\n",
        "}\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return \"\"\n",
        "\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    # Normalize Arabic letters\n",
        "    text = text.translate(ARABIC_NORMALIZATION_MAP)\n",
        "\n",
        "    # Replace English abbreviations\n",
        "    words = text.split()\n",
        "    replaced_words = []\n",
        "    for word in words:\n",
        "        if re.match(r\"^[A-Z]{2,}$\", word):\n",
        "            word = ENGLISH_ABBREVIATIONS.get(word.upper(), word)\n",
        "        replaced_words.append(word)\n",
        "    text = \" \".join(replaced_words)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = re.sub(f\"[{re.escape(ALL_PUNCTUATION)}]\", \" \", text)\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    filtered_tokens = [tok for tok in tokens if tok not in ARABIC_STOPWORDS]\n",
        "\n",
        "    return \" \".join(filtered_tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "for df in [unlabelled_df, labelled_df]:\n",
        "    df[\"Processed Script\"] = df[\"Original Script\"].apply(preprocess_text)\n",
        "\n",
        "print(\"âœ… Preprocessing completed (NLTK tokenization, stopwords, punctuation, newline handled).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Analysis (On Proc) 1\n",
        "\t- Text Sampling\n",
        "\t- Text Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ Checking Unlabelled DataFrame:\n",
            "ğŸ“Œ Sample rows from channel: Da7ee7\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>EpisodeTitle</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Da7ee7</td>\n",
              "      <td>ÙƒÙ„ÙˆØ¨  Ø§Ù„Ø¯Ø­ÙŠØ­</td>\n",
              "      <td>\"ÙƒÙ„ÙˆØ¨\"ØŒ Ø­Ø¨ÙŠØ¨ÙŠØŒ\\nØ§Ø­Ù†Ø§ Ø¹Ø§ÙŠØ²ÙŠÙ† Ù…ØµÙ„Ø­ØªÙƒØŒ\\nØ§Ù†Øª Ù„Ø§Ø²Ù… ...</td>\n",
              "      <td>ÙƒÙ„ÙˆØ¨ Ø­Ø¨ÙŠØ¨ÙŠ Ø§Ø­Ù†Ø§ Ø¹Ø§ÙŠØ²ÙŠÙ† Ù…ØµÙ„Ø­ØªÙƒ Ø§Ù†Øª Ù„Ø§Ø²Ù… ØªØ¹ØªØ²Ù„ Ùˆ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>Da7ee7</td>\n",
              "      <td>Ù…Ø§Ø±ÙƒÙˆ Ø¨ÙˆÙ„Ùˆ  Ø§Ù„Ø¯Ø­ÙŠØ­</td>\n",
              "      <td>Ù‡Ø§ ÙŠØ§ \"Ù…Ø§Ø±ÙƒÙˆ Ø¨ÙˆÙ„Ùˆ\"ØŒ\\nØ¨Ù‚Ø§Ù„Ùƒ Ø³Ù†ÙŠÙ† Ø¨ØªÙ„ÙÙ‘ Ø­ÙˆØ§Ù„ÙŠÙ† Ø§...</td>\n",
              "      <td>Ù‡Ø§ ÙŠØ§ Ù…Ø§Ø±ÙƒÙˆ Ø¨ÙˆÙ„Ùˆ Ø¨Ù‚Ø§Ù„Ùƒ Ø³Ù†ÙŠÙ† Ø¨ØªÙ„ÙÙ‘ Ø­ÙˆØ§Ù„ÙŠÙ† Ø§Ù„Ø¹Ø§Ù„...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>Da7ee7</td>\n",
              "      <td>ÙƒÙˆÙƒØ¨ Ø§Ù„Ù‚Ø±ÙˆØ¯  Ø§Ù„Ø¯Ø­ÙŠØ­</td>\n",
              "      <td>Ù‡Ø§ ÙŠØ§ Ø¥Ù†Ø³Ø§Ù†ØŸ\\nØ¹Ø§Ø¬Ø¨Ùƒ ÙƒØ¯Ø§ Ù…Ù†Ø¸Ø±ÙƒØŸ\\nÙŠØ§Ù‡!\\nØ­Ø±Ø§Ù… Ø¹Ù„ÙŠ...</td>\n",
              "      <td>Ù‡Ø§ ÙŠØ§ Ø§Ù†Ø³Ø§Ù† Ø¹Ø§Ø¬Ø¨Ùƒ ÙƒØ¯Ø§ Ù…Ù†Ø¸Ø±Ùƒ ÙŠØ§Ù‡ Ø­Ø±Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙŠØ§ ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Channel         EpisodeTitle  \\\n",
              "71   Da7ee7         ÙƒÙ„ÙˆØ¨  Ø§Ù„Ø¯Ø­ÙŠØ­   \n",
              "117  Da7ee7   Ù…Ø§Ø±ÙƒÙˆ Ø¨ÙˆÙ„Ùˆ  Ø§Ù„Ø¯Ø­ÙŠØ­   \n",
              "135  Da7ee7  ÙƒÙˆÙƒØ¨ Ø§Ù„Ù‚Ø±ÙˆØ¯  Ø§Ù„Ø¯Ø­ÙŠØ­   \n",
              "\n",
              "                                       Original Script  \\\n",
              "71   \"ÙƒÙ„ÙˆØ¨\"ØŒ Ø­Ø¨ÙŠØ¨ÙŠØŒ\\nØ§Ø­Ù†Ø§ Ø¹Ø§ÙŠØ²ÙŠÙ† Ù…ØµÙ„Ø­ØªÙƒØŒ\\nØ§Ù†Øª Ù„Ø§Ø²Ù… ...   \n",
              "117  Ù‡Ø§ ÙŠØ§ \"Ù…Ø§Ø±ÙƒÙˆ Ø¨ÙˆÙ„Ùˆ\"ØŒ\\nØ¨Ù‚Ø§Ù„Ùƒ Ø³Ù†ÙŠÙ† Ø¨ØªÙ„ÙÙ‘ Ø­ÙˆØ§Ù„ÙŠÙ† Ø§...   \n",
              "135  Ù‡Ø§ ÙŠØ§ Ø¥Ù†Ø³Ø§Ù†ØŸ\\nØ¹Ø§Ø¬Ø¨Ùƒ ÙƒØ¯Ø§ Ù…Ù†Ø¸Ø±ÙƒØŸ\\nÙŠØ§Ù‡!\\nØ­Ø±Ø§Ù… Ø¹Ù„ÙŠ...   \n",
              "\n",
              "                                      Processed Script Category  \n",
              "71   ÙƒÙ„ÙˆØ¨ Ø­Ø¨ÙŠØ¨ÙŠ Ø§Ø­Ù†Ø§ Ø¹Ø§ÙŠØ²ÙŠÙ† Ù…ØµÙ„Ø­ØªÙƒ Ø§Ù†Øª Ù„Ø§Ø²Ù… ØªØ¹ØªØ²Ù„ Ùˆ...           \n",
              "117  Ù‡Ø§ ÙŠØ§ Ù…Ø§Ø±ÙƒÙˆ Ø¨ÙˆÙ„Ùˆ Ø¨Ù‚Ø§Ù„Ùƒ Ø³Ù†ÙŠÙ† Ø¨ØªÙ„ÙÙ‘ Ø­ÙˆØ§Ù„ÙŠÙ† Ø§Ù„Ø¹Ø§Ù„...           \n",
              "135  Ù‡Ø§ ÙŠØ§ Ø§Ù†Ø³Ø§Ù† Ø¹Ø§Ø¬Ø¨Ùƒ ÙƒØ¯Ø§ Ù…Ù†Ø¸Ø±Ùƒ ÙŠØ§Ù‡ Ø­Ø±Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙŠØ§ ...           "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "ğŸ“Œ Sample rows from channel: Elsaha\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>EpisodeTitle</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Elsaha</td>\n",
              "      <td>ØªÙˆØ«ÙŠÙ‚ Ø§Ù„Ù…Ø·Ø¨Ø® Ø§Ù„Ù…ØµØ±ÙŠ.. Ø­ÙƒØ§ÙŠØ© Ø³Ù…ÙŠØ±Ø© Ø¹Ø¨Ø¯Ø§Ù„Ù‚Ø§Ø¯Ø±</td>\n",
              "      <td>Ø§Ø­Ù†Ø§ 7000 Ø³Ù†Ù‡ Ù„Ø§ Ù…Ø´ Ø¹Ø§ÙŠØ²ÙŠÙ† Ø´Ø¹Ø±Ø§Øª Ø§Ø­Ù†Ø§ Ø¨Ø³\\nÙ…ØªØ±Ø¨...</td>\n",
              "      <td>Ø§Ø­Ù†Ø§ 7000 Ø³Ù†Ù‡ Ù…Ø´ Ø¹Ø§ÙŠØ²ÙŠÙ† Ø´Ø¹Ø±Ø§Øª Ø§Ø­Ù†Ø§ Ø¨Ø³ Ù…ØªØ±Ø¨ÙŠÙ† Ø¹...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>Elsaha</td>\n",
              "      <td>Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚Ø§ØªÙ„ Ø£Ù…ÙŠ.. Ø­ÙƒØ§ÙŠØ© Ù†Ø§Ø¯ÙŠØ© Ù…Ø¨Ø±ÙˆÙƒ</td>\n",
              "      <td>ÙƒØ§Ù† Ù…Ø¤Ù„Ù… Ù‚ÙˆÙŠ Ø§Ù† Ø§Ø³ØªØ±Ø¬Ø¹ Ø´Ø¹ÙˆØ± Ø§Ù…ÙŠ Ø¨Ø¹Ø¯ Ù…Ø§\\nØ¶Ø±Ø¨Øª Ø¨...</td>\n",
              "      <td>Ù…Ø¤Ù„Ù… Ù‚ÙˆÙŠ Ø§Ù† Ø§Ø³ØªØ±Ø¬Ø¹ Ø´Ø¹ÙˆØ± Ø§Ù…ÙŠ Ø¶Ø±Ø¨Øª Ø¨Ø§Ù„Ù†Ø§Ø± ÙˆØ§Ø­Ø¯ Ø«...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>Elsaha</td>\n",
              "      <td>Ø·Ø¨ Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ù…Ø³Ù„Ø­Ø©.. Ø­ÙƒØ§ÙŠØ© Ù…ÙŠØ¯Ø§Ù„ÙŠØ© Ø°Ù‡Ø¨ÙŠØ©</td>\n",
              "      <td>ÙÙƒØ±Ù‡ Ø¨ØªØ§Ø¹ØªÙ†Ø§ Ø§Ù„Ù„ÙŠ Ø§Ù†Øª Ø¨ØªÙ‚Ø¯Ù… Ø²ÙŠ ÙƒØ¯Ù‡ Ø§Ùˆ\\nØ´Ø±ÙŠØ­Ù‡ Ø§...</td>\n",
              "      <td>ÙÙƒØ±Ù‡ Ø¨ØªØ§Ø¹ØªÙ†Ø§ Ø§Ù„Ù„ÙŠ Ø§Ù†Øª Ø¨ØªÙ‚Ø¯Ù… Ø²ÙŠ ÙƒØ¯Ù‡ Ø§Ùˆ Ø´Ø±ÙŠØ­Ù‡ Ø§Ù„...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Channel                                 EpisodeTitle  \\\n",
              "167  Elsaha  ØªÙˆØ«ÙŠÙ‚ Ø§Ù„Ù…Ø·Ø¨Ø® Ø§Ù„Ù…ØµØ±ÙŠ.. Ø­ÙƒØ§ÙŠØ© Ø³Ù…ÙŠØ±Ø© Ø¹Ø¨Ø¯Ø§Ù„Ù‚Ø§Ø¯Ø±   \n",
              "191  Elsaha        Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚Ø§ØªÙ„ Ø£Ù…ÙŠ.. Ø­ÙƒØ§ÙŠØ© Ù†Ø§Ø¯ÙŠØ© Ù…Ø¨Ø±ÙˆÙƒ   \n",
              "176  Elsaha      Ø·Ø¨ Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ù…Ø³Ù„Ø­Ø©.. Ø­ÙƒØ§ÙŠØ© Ù…ÙŠØ¯Ø§Ù„ÙŠØ© Ø°Ù‡Ø¨ÙŠØ©   \n",
              "\n",
              "                                       Original Script  \\\n",
              "167  Ø§Ø­Ù†Ø§ 7000 Ø³Ù†Ù‡ Ù„Ø§ Ù…Ø´ Ø¹Ø§ÙŠØ²ÙŠÙ† Ø´Ø¹Ø±Ø§Øª Ø§Ø­Ù†Ø§ Ø¨Ø³\\nÙ…ØªØ±Ø¨...   \n",
              "191  ÙƒØ§Ù† Ù…Ø¤Ù„Ù… Ù‚ÙˆÙŠ Ø§Ù† Ø§Ø³ØªØ±Ø¬Ø¹ Ø´Ø¹ÙˆØ± Ø§Ù…ÙŠ Ø¨Ø¹Ø¯ Ù…Ø§\\nØ¶Ø±Ø¨Øª Ø¨...   \n",
              "176  ÙÙƒØ±Ù‡ Ø¨ØªØ§Ø¹ØªÙ†Ø§ Ø§Ù„Ù„ÙŠ Ø§Ù†Øª Ø¨ØªÙ‚Ø¯Ù… Ø²ÙŠ ÙƒØ¯Ù‡ Ø§Ùˆ\\nØ´Ø±ÙŠØ­Ù‡ Ø§...   \n",
              "\n",
              "                                      Processed Script Category  \n",
              "167  Ø§Ø­Ù†Ø§ 7000 Ø³Ù†Ù‡ Ù…Ø´ Ø¹Ø§ÙŠØ²ÙŠÙ† Ø´Ø¹Ø±Ø§Øª Ø§Ø­Ù†Ø§ Ø¨Ø³ Ù…ØªØ±Ø¨ÙŠÙ† Ø¹...           \n",
              "191  Ù…Ø¤Ù„Ù… Ù‚ÙˆÙŠ Ø§Ù† Ø§Ø³ØªØ±Ø¬Ø¹ Ø´Ø¹ÙˆØ± Ø§Ù…ÙŠ Ø¶Ø±Ø¨Øª Ø¨Ø§Ù„Ù†Ø§Ø± ÙˆØ§Ø­Ø¯ Ø«...           \n",
              "176  ÙÙƒØ±Ù‡ Ø¨ØªØ§Ø¹ØªÙ†Ø§ Ø§Ù„Ù„ÙŠ Ø§Ù†Øª Ø¨ØªÙ‚Ø¯Ù… Ø²ÙŠ ÙƒØ¯Ù‡ Ø§Ùˆ Ø´Ø±ÙŠØ­Ù‡ Ø§Ù„...           "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ğŸ“ Checking Labelled DataFrame:\n",
            "ğŸ“Œ Sample rows from channel: Kefaya Ba2a\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>Episode Title</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Dialogue</th>\n",
              "      <th>Type</th>\n",
              "      <th>Length</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Kefaya Ba2a</td>\n",
              "      <td>Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ - Ø¨Ø·Ø§Ø·Ø³ Ù…Ø´ Ù…Ø­Ù…Ø±Ø©</td>\n",
              "      <td>Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª\\nØ¯Ù‡ ÙŠØ§...</td>\n",
              "      <td>Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚ÙŠ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ø¯Ù‡ ÙŠØ§ Ø¬Ù…Ø§...</td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Kefaya Ba2a</td>\n",
              "      <td>Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ â€œØ¨Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙƒâ€ Ù‚Ø³Ù… ÙˆØ³Ù…Ø¹Ù†ÙŠ Ù¢</td>\n",
              "      <td>Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ù†Ø³Ø®Ù‡\\nØ§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠ...</td>\n",
              "      <td>Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚ÙŠ Ø§Ù„Ù†Ø³Ø®Ù‡ Ø§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠÙ‡ Ø§Ù„...</td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Kefaya Ba2a</td>\n",
              "      <td>Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ â€œØ¨Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙƒâ€ - Ø§Ù„Ø¹Ø³Ù Ø§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠ</td>\n",
              "      <td>Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ù†Ø³Ø®Ù‡\\nØ§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠ...</td>\n",
              "      <td>Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚ÙŠ Ø§Ù„Ù†Ø³Ø®Ù‡ Ø§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠÙ‡ Ø§Ù„...</td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Channel                                    Episode Title  \\\n",
              "12  Kefaya Ba2a               Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ - Ø¨Ø·Ø§Ø·Ø³ Ù…Ø´ Ù…Ø­Ù…Ø±Ø©   \n",
              "18  Kefaya Ba2a      Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ â€œØ¨Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙƒâ€ Ù‚Ø³Ù… ÙˆØ³Ù…Ø¹Ù†ÙŠ Ù¢   \n",
              "16  Kefaya Ba2a  Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠØ© Ø¨Ù‚Ù‰ â€œØ¨Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙƒâ€ - Ø§Ù„Ø¹Ø³Ù Ø§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠ   \n",
              "\n",
              "                                      Original Script  \\\n",
              "12  Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª\\nØ¯Ù‡ ÙŠØ§...   \n",
              "18  Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ù†Ø³Ø®Ù‡\\nØ§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠ...   \n",
              "16  Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚Ù‰ Ø§Ù„Ù†Ø³Ø®Ù‡\\nØ§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠ...   \n",
              "\n",
              "                                     Processed Script Dialogue     Type  \\\n",
              "12  Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚ÙŠ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ø¯Ù‡ ÙŠØ§ Ø¬Ù…Ø§...    false  Podcast   \n",
              "18  Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚ÙŠ Ø§Ù„Ù†Ø³Ø®Ù‡ Ø§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠÙ‡ Ø§Ù„...    false  Podcast   \n",
              "16  Ø§Ù‡Ù„Ø§ Ø¨ÙƒÙ… Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙƒÙØ§ÙŠÙ‡ Ø¨Ù‚ÙŠ Ø§Ù„Ù†Ø³Ø®Ù‡ Ø§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠÙ‡ Ø§Ù„...    false  Podcast   \n",
              "\n",
              "   Length        Category  \n",
              "12         People & Blogs  \n",
              "18         People & Blogs  \n",
              "16         People & Blogs  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "ğŸ“Œ Sample rows from channel: Business Bel Araby\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>Episode Title</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Dialogue</th>\n",
              "      <th>Type</th>\n",
              "      <th>Length</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Business Bel Araby</td>\n",
              "      <td>Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹Ø§Øª Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù‰ Ø§Ù„Ù†Ø¬Ø§Ø­ Ù…Ø¹ Ø¹Ù…Ø± Ø§Ø¨...</td>\n",
              "      <td>Ù„Ø§ Ù‡Ùˆ Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ù‡ Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯ ÙŠØ¹Ù†ÙŠ\\nØ§Ù„Ù†ÙØ³...</td>\n",
              "      <td>Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ù‡ Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯ ÙŠØ¹Ù†ÙŠ Ø§Ù„Ù†ÙØ³ Ø§Ù„Ø·ÙˆÙŠÙ„ ÙŠÙƒ...</td>\n",
              "      <td>true</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>Education</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Business Bel Araby</td>\n",
              "      <td>Ù…Ù† Ù…Ù‡Ù†Ø¯Ø³ Ø§Ù„Ù‰ Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ø¯Ø§Ø±Ø© Ù„Ø´Ø±ÙƒØ© Ù…Ù‚Ø§ÙˆÙ„Ø§Øª - Ø·...</td>\n",
              "      <td>Ø§ÙˆØ­Ø´ Ø­Ø§Ø¬Ù‡ ØªØ¹Ù…Ù„Ù‡Ø§ Ù„Ù†ÙØ³Ùƒ Ø§Ù† Ø§Ù†Øª ÙˆØ§Ù†Øª Ù†Ø§Ø²Ù„\\nØ§Ù„Ø´ØºÙ„...</td>\n",
              "      <td>Ø§ÙˆØ­Ø´ Ø­Ø§Ø¬Ù‡ ØªØ¹Ù…Ù„Ù‡Ø§ Ù„Ù†ÙØ³Ùƒ Ø§Ù† Ø§Ù†Øª ÙˆØ§Ù†Øª Ù†Ø§Ø²Ù„ Ø§Ù„Ø´ØºÙ„ ...</td>\n",
              "      <td>true</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Business Bel Araby</td>\n",
              "      <td>Ø§Ø³Ø±Ø§ Ø§Ù„Ø¨ÙŠØ¹ Ø§Ù„Ø§ÙˆÙ†Ù„Ø§ÙŠÙ† ÙˆÙƒÙŠÙÙŠØ© Ø¨Ù†Ø§Ø¡ Ø¨Ø±Ø§Ù†Ø¯ Ù‚ÙˆÙŠ - Ù…...</td>\n",
              "      <td>ÙˆØ¯Ø§Ø¦Ù…Ø§ Ø§Ù„Ù†Ø§Ø³ Ø¨ØªØ³ØªÙ†Ù‰ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ Ø¹Ø´Ø§Ù†\\nØªØ¨Ø¯Ø§ ÙŠ...</td>\n",
              "      <td>ÙˆØ¯Ø§Ø¦Ù…Ø§ Ø§Ù„Ù†Ø§Ø³ Ø¨ØªØ³ØªÙ†ÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ Ø¹Ø´Ø§Ù† ØªØ¨Ø¯Ø§ ÙŠØ¹...</td>\n",
              "      <td>true</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Channel                                      Episode Title  \\\n",
              "24  Business Bel Araby  Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹Ø§Øª Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù‰ Ø§Ù„Ù†Ø¬Ø§Ø­ Ù…Ø¹ Ø¹Ù…Ø± Ø§Ø¨...   \n",
              "23  Business Bel Araby  Ù…Ù† Ù…Ù‡Ù†Ø¯Ø³ Ø§Ù„Ù‰ Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ø¯Ø§Ø±Ø© Ù„Ø´Ø±ÙƒØ© Ù…Ù‚Ø§ÙˆÙ„Ø§Øª - Ø·...   \n",
              "21  Business Bel Araby  Ø§Ø³Ø±Ø§ Ø§Ù„Ø¨ÙŠØ¹ Ø§Ù„Ø§ÙˆÙ†Ù„Ø§ÙŠÙ† ÙˆÙƒÙŠÙÙŠØ© Ø¨Ù†Ø§Ø¡ Ø¨Ø±Ø§Ù†Ø¯ Ù‚ÙˆÙŠ - Ù…...   \n",
              "\n",
              "                                      Original Script  \\\n",
              "24  Ù„Ø§ Ù‡Ùˆ Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ù‡ Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯ ÙŠØ¹Ù†ÙŠ\\nØ§Ù„Ù†ÙØ³...   \n",
              "23  Ø§ÙˆØ­Ø´ Ø­Ø§Ø¬Ù‡ ØªØ¹Ù…Ù„Ù‡Ø§ Ù„Ù†ÙØ³Ùƒ Ø§Ù† Ø§Ù†Øª ÙˆØ§Ù†Øª Ù†Ø§Ø²Ù„\\nØ§Ù„Ø´ØºÙ„...   \n",
              "21  ÙˆØ¯Ø§Ø¦Ù…Ø§ Ø§Ù„Ù†Ø§Ø³ Ø¨ØªØ³ØªÙ†Ù‰ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ Ø¹Ø´Ø§Ù†\\nØªØ¨Ø¯Ø§ ÙŠ...   \n",
              "\n",
              "                                     Processed Script Dialogue     Type  \\\n",
              "24  Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ù‡ Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯ ÙŠØ¹Ù†ÙŠ Ø§Ù„Ù†ÙØ³ Ø§Ù„Ø·ÙˆÙŠÙ„ ÙŠÙƒ...     true  Podcast   \n",
              "23  Ø§ÙˆØ­Ø´ Ø­Ø§Ø¬Ù‡ ØªØ¹Ù…Ù„Ù‡Ø§ Ù„Ù†ÙØ³Ùƒ Ø§Ù† Ø§Ù†Øª ÙˆØ§Ù†Øª Ù†Ø§Ø²Ù„ Ø§Ù„Ø´ØºÙ„ ...     true  Podcast   \n",
              "21  ÙˆØ¯Ø§Ø¦Ù…Ø§ Ø§Ù„Ù†Ø§Ø³ Ø¨ØªØ³ØªÙ†ÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ Ø¹Ø´Ø§Ù† ØªØ¨Ø¯Ø§ ÙŠØ¹...     true  Podcast   \n",
              "\n",
              "   Length        Category  \n",
              "24              Education  \n",
              "23         People & Blogs  \n",
              "21         People & Blogs  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "ğŸ“Œ Sample rows from channel: B Hodoo2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>Episode Title</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Dialogue</th>\n",
              "      <th>Type</th>\n",
              "      <th>Length</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>B Hodoo2</td>\n",
              "      <td>ÙÙŠØ¯ÙŠÙˆ Ù„Ù† ÙŠØ¹Ø¬Ø¨Ùƒ!!! ÙƒÙ„Ø§Ù… ØµØ±ÙŠØ­ ÙˆØ§Ø¹ØªØ±Ø§ÙØ§Øª Ø®Ø§ØµØ© Ø¹Ù† ...</td>\n",
              "      <td>Ø·Ø¨Ø¹Ø§ ÙƒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ø§Ø­Ù†Ø§ Ø§ØªØ¹ÙˆØ¯Ù†Ø§ Ø§Ù† Ø§ÙŠ ÙÙŠØ¯ÙŠÙˆ\\nÙŠØ¨Ø¯Ø§ Ù„Ø§...</td>\n",
              "      <td>Ø·Ø¨Ø¹Ø§ ÙƒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ø§Ø­Ù†Ø§ Ø§ØªØ¹ÙˆØ¯Ù†Ø§ Ø§Ù† Ø§ÙŠ ÙÙŠØ¯ÙŠÙˆ ÙŠØ¨Ø¯Ø§ Ù„Ø§Ø²...</td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>Education</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>B Hodoo2</td>\n",
              "      <td>Ø¥Ø²Ø§ÙŠ Ø¶Ø§Ø¹ÙØª Ø¯Ø®Ù„ÙŠ Ø¨Ø¯ÙˆÙ† Ø´ØºÙ„ Ø¥Ø¶Ø§ÙÙŠ! - Ø¹Ù† Ø§Ù„Ø±Ø²Ù‚ ÙˆÙˆØ³...</td>\n",
              "      <td>Ø§Ù†Ø§ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡ Ø¬Ø§ÙŠ Ø§Ù‚ÙˆÙ„Ù„Ùƒ Ø§Ø²Ø§ÙŠ ØªØ²ÙˆØ¯ Ù…Ù†\\nØ¯Ø®Ù„Ùƒ Ø§Ù„Ù…...</td>\n",
              "      <td>Ø§Ù†Ø§ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡ Ø¬Ø§ÙŠ Ø§Ù‚ÙˆÙ„Ù„Ùƒ Ø§Ø²Ø§ÙŠ ØªØ²ÙˆØ¯ Ø¯Ø®Ù„Ùƒ Ø§Ù„Ù…Ø§Ø¯ÙŠ ...</td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>Education</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>B Hodoo2</td>\n",
              "      <td>Ù…ÙŠÙ† Ù‡ÙŠÙ†Ù‚Ø°Ùƒ Ù„Ùˆ ØºØ±ÙØªØŸ _ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ø¨Ù‡Ø¯ÙˆØ¡ Ù…Ø¹ ÙƒØ±ÙŠÙ… _ ...</td>\n",
              "      <td>ØªØ³Ø§Ø¤Ù„ Ù‚Ø±ÙŠØªÙ‡ Ø¹Ù„Ù‰ Ø§Ù„ÙÙŠØ³Ø¨ÙˆÙƒ Ø¹Ù„ÙŠÙ‡ Ø§ÙƒØªØ± Ù…Ù†\\n3000 Ø´ÙŠ...</td>\n",
              "      <td>ØªØ³Ø§Ø¤Ù„ Ù‚Ø±ÙŠØªÙ‡ Ø¹Ù„ÙŠ Ø§Ù„ÙÙŠØ³Ø¨ÙˆÙƒ Ø¹Ù„ÙŠÙ‡ Ø§ÙƒØªØ± 3000 Ø´ÙŠØ± Ø§Ù‚...</td>\n",
              "      <td>false</td>\n",
              "      <td>Podcast</td>\n",
              "      <td></td>\n",
              "      <td>Education</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Channel                                      Episode Title  \\\n",
              "35  B Hodoo2  ÙÙŠØ¯ÙŠÙˆ Ù„Ù† ÙŠØ¹Ø¬Ø¨Ùƒ!!! ÙƒÙ„Ø§Ù… ØµØ±ÙŠØ­ ÙˆØ§Ø¹ØªØ±Ø§ÙØ§Øª Ø®Ø§ØµØ© Ø¹Ù† ...   \n",
              "27  B Hodoo2  Ø¥Ø²Ø§ÙŠ Ø¶Ø§Ø¹ÙØª Ø¯Ø®Ù„ÙŠ Ø¨Ø¯ÙˆÙ† Ø´ØºÙ„ Ø¥Ø¶Ø§ÙÙŠ! - Ø¹Ù† Ø§Ù„Ø±Ø²Ù‚ ÙˆÙˆØ³...   \n",
              "48  B Hodoo2  Ù…ÙŠÙ† Ù‡ÙŠÙ†Ù‚Ø°Ùƒ Ù„Ùˆ ØºØ±ÙØªØŸ _ Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ø¨Ù‡Ø¯ÙˆØ¡ Ù…Ø¹ ÙƒØ±ÙŠÙ… _ ...   \n",
              "\n",
              "                                      Original Script  \\\n",
              "35  Ø·Ø¨Ø¹Ø§ ÙƒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ø§Ø­Ù†Ø§ Ø§ØªØ¹ÙˆØ¯Ù†Ø§ Ø§Ù† Ø§ÙŠ ÙÙŠØ¯ÙŠÙˆ\\nÙŠØ¨Ø¯Ø§ Ù„Ø§...   \n",
              "27  Ø§Ù†Ø§ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡ Ø¬Ø§ÙŠ Ø§Ù‚ÙˆÙ„Ù„Ùƒ Ø§Ø²Ø§ÙŠ ØªØ²ÙˆØ¯ Ù…Ù†\\nØ¯Ø®Ù„Ùƒ Ø§Ù„Ù…...   \n",
              "48  ØªØ³Ø§Ø¤Ù„ Ù‚Ø±ÙŠØªÙ‡ Ø¹Ù„Ù‰ Ø§Ù„ÙÙŠØ³Ø¨ÙˆÙƒ Ø¹Ù„ÙŠÙ‡ Ø§ÙƒØªØ± Ù…Ù†\\n3000 Ø´ÙŠ...   \n",
              "\n",
              "                                     Processed Script Dialogue     Type  \\\n",
              "35  Ø·Ø¨Ø¹Ø§ ÙƒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ø§Ø­Ù†Ø§ Ø§ØªØ¹ÙˆØ¯Ù†Ø§ Ø§Ù† Ø§ÙŠ ÙÙŠØ¯ÙŠÙˆ ÙŠØ¨Ø¯Ø§ Ù„Ø§Ø²...    false  Podcast   \n",
              "27  Ø§Ù†Ø§ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡ Ø¬Ø§ÙŠ Ø§Ù‚ÙˆÙ„Ù„Ùƒ Ø§Ø²Ø§ÙŠ ØªØ²ÙˆØ¯ Ø¯Ø®Ù„Ùƒ Ø§Ù„Ù…Ø§Ø¯ÙŠ ...    false  Podcast   \n",
              "48  ØªØ³Ø§Ø¤Ù„ Ù‚Ø±ÙŠØªÙ‡ Ø¹Ù„ÙŠ Ø§Ù„ÙÙŠØ³Ø¨ÙˆÙƒ Ø¹Ù„ÙŠÙ‡ Ø§ÙƒØªØ± 3000 Ø´ÙŠØ± Ø§Ù‚...    false  Podcast   \n",
              "\n",
              "   Length   Category  \n",
              "35         Education  \n",
              "27         Education  \n",
              "48         Education  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "ğŸ“Œ Sample rows from channel: Fi_Al_Hadaraa\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>Episode Title</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Dialogue</th>\n",
              "      <th>Type</th>\n",
              "      <th>Length</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Fi_Al_Hadaraa</td>\n",
              "      <td>ØµØ¯ÙŠÙ‚ÙŠ_Ø§Ù„Ø¥Ù†Ø³Ø§Ù†_Ø¨ØªØ­Ø¨_Ø§Ù„ØµØ¯Ø±_ÙˆÙ„Ø§_Ø§Ù„ÙˆØ±Ùƒ__ÙÙŠ_Ø§Ù„Ø­Ø¶Ø§Ø±Ø©</td>\n",
              "      <td>Ø·Ø¨ Ø§ÙŠÙ‡\\nØ§Ù„Ù„ÙŠÙ„ Ø¨ÙŠØ®Ù„Øµ ÙˆÙƒØ§ØªØ¨ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨ÙŠØºÙ„Ù‚ ØµÙØ­Ø§ØªÙ‡...</td>\n",
              "      <td>Ø·Ø¨ Ø§ÙŠÙ‡ Ø§Ù„Ù„ÙŠÙ„ Ø¨ÙŠØ®Ù„Øµ ÙˆÙƒØ§ØªØ¨ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨ÙŠØºÙ„Ù‚ ØµÙØ­Ø§ØªÙ‡ ...</td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:17:09</td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Fi_Al_Hadaraa</td>\n",
              "      <td>Ù‡Ø§Ù„Ø§Ù†Ø¯_ØªØ±ÙŠØ¨Ù„_ÙƒØ§Ø¨ØªÙ†__ÙÙŠ_Ø§Ù„Ø­Ø¶Ø§Ø±Ø©</td>\n",
              "      <td>ÙŠØ¹Ù†ÙŠ Ø®Ù„Ø§ØµØŸ\\nÙ…Ø§ ÙÙŠØ´ Ù…Ù†Ù‘Ù‡ ØªØ§Ù†ÙŠØŸ\\nÙ…Ø§ Ø®Ù„Ø§Øµ Ø¨Ù‚Ù‰ ÙŠØ§ ...</td>\n",
              "      <td>ÙŠØ¹Ù†ÙŠ Ø®Ù„Ø§Øµ ÙÙŠØ´ Ù…Ù†Ù‘Ù‡ ØªØ§Ù†ÙŠ Ø®Ù„Ø§Øµ Ø¨Ù‚ÙŠ ÙŠØ§ Ù†Ø¬Ù… ÙƒØ¨Ø±Ù†Ø§ ...</td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:24:18</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Fi_Al_Hadaraa</td>\n",
              "      <td>Ù…ØªÙ„Ø§Ø²Ù…Ø©_Ø§Ù„Ù…Ø­ØªØ§Ù„__ØµØ¯ÙŠÙ‚ÙŠ_Ø§Ù„Ø§Ù†Ø³Ø§Ù†_Ù‡Ù„_ØªØ³ØªØ­Ù‚_Ù…Ù†ØµØ¨Ùƒ_...</td>\n",
              "      <td>Ø£ÙŠÙˆØ©ØŒ Ø­Ø§Ø¶Ø±.\\nØ£ÙŠÙˆØ©.\\n\"Ø±ÙŠÙ…\"ØŸ!\\nØ¥ÙŠÙ‡ ÙŠØ§ Ø¨Ù†ØªÙŠ Ø§Ù„Ù„ÙŠ ...</td>\n",
              "      <td>Ø§ÙŠÙˆÙ‡ Ø­Ø§Ø¶Ø± Ø§ÙŠÙˆÙ‡ Ø±ÙŠÙ… Ø§ÙŠÙ‡ ÙŠØ§ Ø¨Ù†ØªÙŠ Ø§Ù„Ù„ÙŠ Ø§Ù†ØªÙŠ Ø¹Ø§Ù…Ù„Ø§...</td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:13:07</td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Channel                                      Episode Title  \\\n",
              "72  Fi_Al_Hadaraa     ØµØ¯ÙŠÙ‚ÙŠ_Ø§Ù„Ø¥Ù†Ø³Ø§Ù†_Ø¨ØªØ­Ø¨_Ø§Ù„ØµØ¯Ø±_ÙˆÙ„Ø§_Ø§Ù„ÙˆØ±Ùƒ__ÙÙŠ_Ø§Ù„Ø­Ø¶Ø§Ø±Ø©   \n",
              "94  Fi_Al_Hadaraa                     Ù‡Ø§Ù„Ø§Ù†Ø¯_ØªØ±ÙŠØ¨Ù„_ÙƒØ§Ø¨ØªÙ†__ÙÙŠ_Ø§Ù„Ø­Ø¶Ø§Ø±Ø©   \n",
              "82  Fi_Al_Hadaraa  Ù…ØªÙ„Ø§Ø²Ù…Ø©_Ø§Ù„Ù…Ø­ØªØ§Ù„__ØµØ¯ÙŠÙ‚ÙŠ_Ø§Ù„Ø§Ù†Ø³Ø§Ù†_Ù‡Ù„_ØªØ³ØªØ­Ù‚_Ù…Ù†ØµØ¨Ùƒ_...   \n",
              "\n",
              "                                      Original Script  \\\n",
              "72  Ø·Ø¨ Ø§ÙŠÙ‡\\nØ§Ù„Ù„ÙŠÙ„ Ø¨ÙŠØ®Ù„Øµ ÙˆÙƒØ§ØªØ¨ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨ÙŠØºÙ„Ù‚ ØµÙØ­Ø§ØªÙ‡...   \n",
              "94  ÙŠØ¹Ù†ÙŠ Ø®Ù„Ø§ØµØŸ\\nÙ…Ø§ ÙÙŠØ´ Ù…Ù†Ù‘Ù‡ ØªØ§Ù†ÙŠØŸ\\nÙ…Ø§ Ø®Ù„Ø§Øµ Ø¨Ù‚Ù‰ ÙŠØ§ ...   \n",
              "82  Ø£ÙŠÙˆØ©ØŒ Ø­Ø§Ø¶Ø±.\\nØ£ÙŠÙˆØ©.\\n\"Ø±ÙŠÙ…\"ØŸ!\\nØ¥ÙŠÙ‡ ÙŠØ§ Ø¨Ù†ØªÙŠ Ø§Ù„Ù„ÙŠ ...   \n",
              "\n",
              "                                     Processed Script Dialogue     Type  \\\n",
              "72  Ø·Ø¨ Ø§ÙŠÙ‡ Ø§Ù„Ù„ÙŠÙ„ Ø¨ÙŠØ®Ù„Øµ ÙˆÙƒØ§ØªØ¨ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨ÙŠØºÙ„Ù‚ ØµÙØ­Ø§ØªÙ‡ ...           Youtube   \n",
              "94  ÙŠØ¹Ù†ÙŠ Ø®Ù„Ø§Øµ ÙÙŠØ´ Ù…Ù†Ù‘Ù‡ ØªØ§Ù†ÙŠ Ø®Ù„Ø§Øµ Ø¨Ù‚ÙŠ ÙŠØ§ Ù†Ø¬Ù… ÙƒØ¨Ø±Ù†Ø§ ...           Youtube   \n",
              "82  Ø§ÙŠÙˆÙ‡ Ø­Ø§Ø¶Ø± Ø§ÙŠÙˆÙ‡ Ø±ÙŠÙ… Ø§ÙŠÙ‡ ÙŠØ§ Ø¨Ù†ØªÙŠ Ø§Ù„Ù„ÙŠ Ø§Ù†ØªÙŠ Ø¹Ø§Ù…Ù„Ø§...           Youtube   \n",
              "\n",
              "      Length        Category  \n",
              "72  00:17:09  People & Blogs  \n",
              "94  00:24:18   Entertainment  \n",
              "82  00:13:07  People & Blogs  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "ğŸ“Œ Sample rows from channel: Al_Mokhbir_Al_Eqtisadi\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel</th>\n",
              "      <th>Episode Title</th>\n",
              "      <th>Original Script</th>\n",
              "      <th>Processed Script</th>\n",
              "      <th>Dialogue</th>\n",
              "      <th>Type</th>\n",
              "      <th>Length</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>Al_Mokhbir_Al_Eqtisadi</td>\n",
              "      <td>Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ___Ù„Ù…Ø§Ø°Ø§_Ù‚Ø¯_ÙŠÙ†Ù‡Ø§Ø±_Ø§Ù‚ØªØµØ§Ø¯_Ø£Ù…Ø±ÙŠÙƒ...</td>\n",
              "      <td>ÙÙŠ ÙØ¨Ø±Ø§ÙŠØ± 2023\\nÙŠØ¹Ù†ÙŠ Ø¨Ø¹Ø¯ Ø§Ø±Ø¨Ø¹ Ø³Ù†ÙŠÙ† ØªÙ‚Ø±ÙŠØ¨Ø§ Ù…Ù† Ø§...</td>\n",
              "      <td>ÙØ¨Ø±Ø§ÙŠØ± 2023 ÙŠØ¹Ù†ÙŠ Ø§Ø±Ø¨Ø¹ Ø³Ù†ÙŠÙ† ØªÙ‚Ø±ÙŠØ¨Ø§ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡ Ø·Ø¨Ø¹...</td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:14:17</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>Al_Mokhbir_Al_Eqtisadi</td>\n",
              "      <td>Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ_Ù„Ù…Ø§Ø°Ø§_Ø³ØªØ®ØªÙÙŠ_ÙƒÙ…ÙŠØ§Øª_Ø¶Ø®Ù…Ø©_Ù…Ù†_Ø§Ù„...</td>\n",
              "      <td>ÙÙŠ 31 Ù…Ø§Ø±Ø³ Ø§Ù„Ù„ÙŠ ÙØ§Øª\\nØ§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„ØµÙŠÙ†ÙŠ Ø´ÙŠ Ø¬ÙŠÙ† Ø¨ÙŠÙ†Øº...</td>\n",
              "      <td>31 Ù…Ø§Ø±Ø³ Ø§Ù„Ù„ÙŠ ÙØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„ØµÙŠÙ†ÙŠ Ø´ÙŠ Ø¬ÙŠÙ† Ø¨ÙŠÙ†Øº Ù†Ø´Ø±...</td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:13:25</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>Al_Mokhbir_Al_Eqtisadi</td>\n",
              "      <td>Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ__ÙƒÙŠÙ_ØªØ±ÙØ¹_Ø§Ù„Ø´Ø±ÙƒØ§Øª_Ø£Ø³Ø¹Ø§Ø±_Ø§Ù„Ù…Ù†Øª...</td>\n",
              "      <td>ÙÙŠ Ø§ÙˆØ§Ø®Ø± 2016 Ø­ØµÙ„ Ù‡Ø¬ÙˆÙ… ÙƒØ¨ÙŠØ± Ù…Ù†\\nØ§Ù„Ù…Ø³ØªÙ‡Ù„ÙƒÙŠÙ† ÙÙŠ ...</td>\n",
              "      <td>Ø§ÙˆØ§Ø®Ø± 2016 Ø­ØµÙ„ Ù‡Ø¬ÙˆÙ… ÙƒØ¨ÙŠØ± Ø§Ù„Ù…Ø³ØªÙ‡Ù„ÙƒÙŠÙ† Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ§ Ø¹...</td>\n",
              "      <td></td>\n",
              "      <td>Youtube</td>\n",
              "      <td>00:15:12</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Channel  \\\n",
              "166  Al_Mokhbir_Al_Eqtisadi   \n",
              "293  Al_Mokhbir_Al_Eqtisadi   \n",
              "263  Al_Mokhbir_Al_Eqtisadi   \n",
              "\n",
              "                                         Episode Title  \\\n",
              "166  Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ___Ù„Ù…Ø§Ø°Ø§_Ù‚Ø¯_ÙŠÙ†Ù‡Ø§Ø±_Ø§Ù‚ØªØµØ§Ø¯_Ø£Ù…Ø±ÙŠÙƒ...   \n",
              "293  Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ_Ù„Ù…Ø§Ø°Ø§_Ø³ØªØ®ØªÙÙŠ_ÙƒÙ…ÙŠØ§Øª_Ø¶Ø®Ù…Ø©_Ù…Ù†_Ø§Ù„...   \n",
              "263  Ø§Ù„Ù…Ø®Ø¨Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ__ÙƒÙŠÙ_ØªØ±ÙØ¹_Ø§Ù„Ø´Ø±ÙƒØ§Øª_Ø£Ø³Ø¹Ø§Ø±_Ø§Ù„Ù…Ù†Øª...   \n",
              "\n",
              "                                       Original Script  \\\n",
              "166  ÙÙŠ ÙØ¨Ø±Ø§ÙŠØ± 2023\\nÙŠØ¹Ù†ÙŠ Ø¨Ø¹Ø¯ Ø§Ø±Ø¨Ø¹ Ø³Ù†ÙŠÙ† ØªÙ‚Ø±ÙŠØ¨Ø§ Ù…Ù† Ø§...   \n",
              "293  ÙÙŠ 31 Ù…Ø§Ø±Ø³ Ø§Ù„Ù„ÙŠ ÙØ§Øª\\nØ§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„ØµÙŠÙ†ÙŠ Ø´ÙŠ Ø¬ÙŠÙ† Ø¨ÙŠÙ†Øº...   \n",
              "263  ÙÙŠ Ø§ÙˆØ§Ø®Ø± 2016 Ø­ØµÙ„ Ù‡Ø¬ÙˆÙ… ÙƒØ¨ÙŠØ± Ù…Ù†\\nØ§Ù„Ù…Ø³ØªÙ‡Ù„ÙƒÙŠÙ† ÙÙŠ ...   \n",
              "\n",
              "                                      Processed Script Dialogue     Type  \\\n",
              "166  ÙØ¨Ø±Ø§ÙŠØ± 2023 ÙŠØ¹Ù†ÙŠ Ø§Ø±Ø¨Ø¹ Ø³Ù†ÙŠÙ† ØªÙ‚Ø±ÙŠØ¨Ø§ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡ Ø·Ø¨Ø¹...           Youtube   \n",
              "293  31 Ù…Ø§Ø±Ø³ Ø§Ù„Ù„ÙŠ ÙØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„ØµÙŠÙ†ÙŠ Ø´ÙŠ Ø¬ÙŠÙ† Ø¨ÙŠÙ†Øº Ù†Ø´Ø±...           Youtube   \n",
              "263  Ø§ÙˆØ§Ø®Ø± 2016 Ø­ØµÙ„ Ù‡Ø¬ÙˆÙ… ÙƒØ¨ÙŠØ± Ø§Ù„Ù…Ø³ØªÙ‡Ù„ÙƒÙŠÙ† Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ§ Ø¹...           Youtube   \n",
              "\n",
              "       Length       Category  \n",
              "166  00:14:17  Entertainment  \n",
              "293  00:13:25  Entertainment  \n",
              "263  00:15:12  Entertainment  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def sample_rows_per_channel(df, channel_column=\"Channel\", num_samples=3):\n",
        "    unique_channels = df[channel_column].unique()\n",
        "    for channel in unique_channels:\n",
        "        print(f\"ğŸ“Œ Sample rows from channel: {channel}\")\n",
        "        display(df[df[channel_column] == channel].sample(min(num_samples, len(df[df[channel_column] == channel]))))\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "print(\"ğŸ“ Checking Unlabelled DataFrame:\")\n",
        "sample_rows_per_channel(unlabelled_df)\n",
        "\n",
        "print(\"\\nğŸ“ Checking Labelled DataFrame:\")\n",
        "sample_rows_per_channel(labelled_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Data Preparation\n",
        "\t- Category selection? Handle Class Imbalance\n",
        "\t- Feature extraction (bag of words, TF-IDF, word embeddings / vectorization)\n",
        "\t- Encoding\n",
        "\t- Data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Collecting imbalanced-learn (from imblearn)\n",
            "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
            "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
            "Installing collected packages: imbalanced-learn, imblearn\n",
            "Successfully installed imbalanced-learn-0.12.4 imblearn-0.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category distribution:\n",
            "Category\n",
            "Entertainment     229\n",
            "People & Blogs     72\n",
            "Education          24\n",
            "Comedy              4\n",
            "                    2\n",
            "Name: count, dtype: int64\n",
            "Original dataset size: 331\n",
            "Filtered dataset size: 325\n",
            "\n",
            "Category encoding mapping:\n",
            "Education -> 0\n",
            "Entertainment -> 1\n",
            "People & Blogs -> 2\n",
            "\n",
            "Class distribution before SMOTE:\n",
            "Counter({1: 183, 2: 58, 0: 19})\n",
            "\n",
            "Class distribution after SMOTE:\n",
            "Counter({1: 183, 2: 183, 0: 183})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sherifahammoud/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training set shape: (549, 34982)\n",
            "Testing set shape: (65, 34982)\n",
            "Unlabelled data shape: (193, 34982)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# 1. Category Selection and Class Imbalance Handling\n",
        "print(\"Category distribution:\")\n",
        "category_counts = labelled_df['Category'].value_counts()\n",
        "print(category_counts)\n",
        "\n",
        "# Handling class imbalance options:\n",
        "# a. Remove categories with very few samples (optional)\n",
        "MIN_SAMPLES = 5\n",
        "valid_categories = category_counts[category_counts >=\n",
        "                                   MIN_SAMPLES].index.tolist()\n",
        "filtered_df = labelled_df[labelled_df['Category'].isin(valid_categories)]\n",
        "\n",
        "print(f\"Original dataset size: {len(labelled_df)}\")\n",
        "print(f\"Filtered dataset size: {len(filtered_df)}\")\n",
        "\n",
        "# 2. Feature Extraction\n",
        "# Choose one of the following feature extraction methods:\n",
        "\n",
        "# Option 1: Bag of Words\n",
        "count_vectorizer = CountVectorizer(min_df=2, max_df=0.95)\n",
        "X_bow = count_vectorizer.fit_transform(filtered_df['Processed Script'])\n",
        "\n",
        "# Option 2: TF-IDF (usually performs better for text classification)\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=2, max_df=0.95)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(filtered_df['Processed Script'])\n",
        "\n",
        "# Let's use TF-IDF for our primary feature set\n",
        "X = X_tfidf\n",
        "\n",
        "# 3. Encoding the target variable (categories)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(filtered_df['Category'])\n",
        "\n",
        "# Display the encoding mapping\n",
        "category_mapping = dict(\n",
        "    zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
        "print(\"\\nCategory encoding mapping:\")\n",
        "for category, code in category_mapping.items():\n",
        "    print(f\"{category} -> {code}\")\n",
        "\n",
        "# 4. Data Splitting\n",
        "# Split data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 5. Further handle class imbalance with SMOTE (only on training data)\n",
        "print(\"\\nClass distribution before SMOTE:\")\n",
        "print(Counter(y_train))\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nClass distribution after SMOTE:\")\n",
        "print(Counter(y_train_resampled))\n",
        "\n",
        "# 6. Prepare a function to process and vectorize unlabelled data\n",
        "def prepare_unlabelled_data(unlabelled_df, vectorizer):\n",
        "    \"\"\"Process and vectorize unlabelled data using the same vectorizer as the training data\"\"\"\n",
        "    X_unlabelled = vectorizer.transform(unlabelled_df['Processed Script'])\n",
        "    return X_unlabelled\n",
        "\n",
        "\n",
        "# Process unlabelled data using the same vectorizer\n",
        "X_unlabelled = prepare_unlabelled_data(unlabelled_df, tfidf_vectorizer)\n",
        "\n",
        "print(f\"\\nTraining set shape: {X_train_resampled.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}\")\n",
        "print(f\"Unlabelled data shape: {X_unlabelled.shape}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
