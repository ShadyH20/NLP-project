{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adtfwaAwCPq0"
   },
   "source": [
    "### Installation & Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T21:13:21.467288Z",
     "iopub.status.busy": "2025-04-22T21:13:21.466610Z",
     "iopub.status.idle": "2025-04-22T21:13:25.847235Z",
     "shell.execute_reply": "2025-04-22T21:13:25.846554Z",
     "shell.execute_reply.started": "2025-04-22T21:13:21.467261Z"
    },
    "executionInfo": {
     "elapsed": 8793,
     "status": "ok",
     "timestamp": 1745185615542,
     "user": {
      "displayName": "Sherifa Hammoud",
      "userId": "01658453922136634541"
     },
     "user_tz": -120
    },
    "id": "V3oNJP0SCHgb",
    "outputId": "6688ee3a-7b98-44ea-95bf-2c753e0f02b5",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2024.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T21:13:28.903649Z",
     "iopub.status.busy": "2025-04-22T21:13:28.903364Z",
     "iopub.status.idle": "2025-04-22T21:15:38.055504Z",
     "shell.execute_reply": "2025-04-22T21:15:38.054821Z",
     "shell.execute_reply.started": "2025-04-22T21:13:28.903624Z"
    },
    "executionInfo": {
     "elapsed": 4383,
     "status": "ok",
     "timestamp": 1745185619928,
     "user": {
      "displayName": "Sherifa Hammoud",
      "userId": "01658453922136634541"
     },
     "user_tz": -120
    },
    "id": "CuBL8BGY-p7X",
    "outputId": "48291094-3214-4046-cf0f-79c542351876",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torchtext==0.17.0\n",
      "  Downloading https://download.pytorch.org/whl/torchtext-0.17.0%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.32.3)\n",
      "Collecting torch==2.2.0 (from torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.0%2Bcu118-cp311-cp311-linux_x86_64.whl (811.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.7/811.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (1.26.4)\n",
      "Collecting torchdata==0.7.1 (from torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (4.13.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2024.12.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.19.3 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m25.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.2.0 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.17.0) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0->torchtext==0.17.0) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtext==0.17.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtext==0.17.0) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchtext==0.17.0) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchtext==0.17.0) (2024.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->torchtext==0.17.0) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchtext==0.17.0) (2024.2.0)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchdata, torchtext\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu124\n",
      "    Uninstalling torch-2.5.1+cu124:\n",
      "      Successfully uninstalled torch-2.5.1+cu124\n",
      "  Attempting uninstall: torchdata\n",
      "    Found existing installation: torchdata 0.11.0\n",
      "    Uninstalling torchdata-0.11.0:\n",
      "      Successfully uninstalled torchdata-0.11.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.1 which is incompatible.\n",
      "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.2.0+cu118 which is incompatible.\n",
      "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 torch-2.2.0+cu118 torchdata-0.7.1 torchtext-0.17.0+cpu triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.17.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T21:16:06.934573Z",
     "iopub.status.busy": "2025-04-22T21:16:06.934278Z",
     "iopub.status.idle": "2025-04-22T21:16:10.459294Z",
     "shell.execute_reply": "2025-04-22T21:16:10.458466Z",
     "shell.execute_reply.started": "2025-04-22T21:16:06.934548Z"
    },
    "executionInfo": {
     "elapsed": 5182,
     "status": "ok",
     "timestamp": 1745185625112,
     "user": {
      "displayName": "Sherifa Hammoud",
      "userId": "01658453922136634541"
     },
     "user_tz": -120
    },
    "id": "W9Q8pHZ2-HLZ",
    "outputId": "37046b77-2455-4716-966f-9afb71d80b00",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.2.0+cu118\n",
      "torchtext version: 0.17.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(f'torchtext version: {torchtext.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNL7-BZQCIJM"
   },
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T21:33:11.276350Z",
     "iopub.status.busy": "2025-04-22T21:33:11.275808Z",
     "iopub.status.idle": "2025-04-22T21:33:37.190329Z",
     "shell.execute_reply": "2025-04-22T21:33:37.189605Z",
     "shell.execute_reply.started": "2025-04-22T21:33:11.276328Z"
    },
    "executionInfo": {
     "elapsed": 36508,
     "status": "ok",
     "timestamp": 1745185661622,
     "user": {
      "displayName": "Sherifa Hammoud",
      "userId": "01658453922136634541"
     },
     "user_tz": -120
    },
    "id": "t5Fdg-h4zPFE",
    "outputId": "042e504e-ae1d-4d0f-f082-47bf2a227fca",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "181\n",
      "                                                 context  \\\n",
      "12947  The Oklahoma School of Science and Mathematics...   \n",
      "12697  In the past, the Malays used to call the Portu...   \n",
      "\n",
      "                                                question  \\\n",
      "12947  Where is The Oklahoma School of Science and Ma...   \n",
      "12697                  What does the term refer to now?    \n",
      "\n",
      "                                        answer  \\\n",
      "12947                            Oklahoma City   \n",
      "12697  the modern Kristang creoles of Malaysia   \n",
      "\n",
      "                                             context_tok  \\\n",
      "12947  [the, oklahoma, school, of, science, and, math...   \n",
      "12697  [in, the, past, ,, the, malays, used, to, call...   \n",
      "\n",
      "                                            question_tok  \\\n",
      "12947  [where, is, the, oklahoma, school, of, science...   \n",
      "12697         [what, does, the, term, refer, to, now, ?]   \n",
      "\n",
      "                                           answer_tok  \n",
      "12947                                [oklahoma, city]  \n",
      "12697  [the, modern, kristang, creoles, of, malaysia]  \n",
      "(0, 6)\n",
      "1\n",
      "160\n",
      "                                                context  \\\n",
      "1490  On 7 January 1900, Tesla left Colorado Springs...   \n",
      "1491  On 7 January 1900, Tesla left Colorado Springs...   \n",
      "\n",
      "                                          question                 answer  \\\n",
      "1490  When did Tesla depart from Colorado Springs?                   1900   \n",
      "1491                     What happened to his lab?  His lab was torn down   \n",
      "\n",
      "                                            context_tok  \\\n",
      "1490  [on, 7, january, 1900, ,, tesla, left, colorad...   \n",
      "1491  [on, 7, january, 1900, ,, tesla, left, colorad...   \n",
      "\n",
      "                                           question_tok  \\\n",
      "1490  [when, did, tesla, depart, from, colorado, spr...   \n",
      "1491                  [what, happened, to, his, lab, ?]   \n",
      "\n",
      "                       answer_tok  \n",
      "1490                       [1900]  \n",
      "1491  [his, lab, was, torn, down]  \n",
      "(0, 6)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import GloVe\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "dataset = load_dataset('squad')\n",
    "\n",
    "def dataset_to_dataframe(ds, limit=20000):\n",
    "    df = pd.DataFrame(ds)\n",
    "    \n",
    "    df['context_len'] = df['context'].apply(len)\n",
    "    df_sorted = df.sort_values(by='context_len').iloc[:limit]\n",
    "    \n",
    "    df_sorted = df_sorted[['context', 'question', 'answers']]\n",
    "    \n",
    "    df_sorted['answer'] = df_sorted['answers'].apply(lambda x: x['text'][0])\n",
    "    \n",
    "    # minimum answers length and maximum\n",
    "    print(df_sorted['answer'].apply(len).min())\n",
    "    print(df_sorted['answer'].apply(len).max())\n",
    "    \n",
    "    df_sorted.drop(columns=['answers'], inplace=True)\n",
    "    \n",
    "    df_sorted['context_tok'] = df_sorted['context'].apply(lambda x: word_tokenize(x.lower()))\n",
    "    df_sorted['question_tok'] = df_sorted['question'].apply(lambda x: word_tokenize(x.lower()))\n",
    "    df_sorted['answer_tok'] = df_sorted['answer'].apply(lambda x: word_tokenize(x.lower()))\n",
    "    \n",
    "    print(df_sorted.head(2))\n",
    "    \n",
    "    # print how many have no answer\n",
    "    print(df_sorted[df_sorted['answer'] == ''].shape)\n",
    "\n",
    "    return df_sorted\n",
    "\n",
    "train_df_sorted = dataset_to_dataframe(dataset['train'], limit=20000)\n",
    "val_df_sorted = dataset_to_dataframe(dataset['validation'], limit=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62xRU1SMCBBk"
   },
   "source": [
    "### Build Vocabulary & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T21:33:42.446806Z",
     "iopub.status.busy": "2025-04-22T21:33:42.446545Z",
     "iopub.status.idle": "2025-04-22T21:33:45.148793Z",
     "shell.execute_reply": "2025-04-22T21:33:45.148147Z",
     "shell.execute_reply.started": "2025-04-22T21:33:42.446788Z"
    },
    "id": "IwgQpkNozZdl",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "def preprocess_data(df, vocab=None, max_vocab_size=25000, glove_dim=100):\n",
    "    special_tokens = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
    "\n",
    "    if vocab is None:\n",
    "        # Flatten tokens from all sources into a single iterator\n",
    "        def yield_tokens():\n",
    "            for tokens in itertools.chain(\n",
    "                df['context_tok'],\n",
    "                df['question_tok'],\n",
    "                df['answer_tok']\n",
    "            ):\n",
    "                yield tokens\n",
    "\n",
    "        # Build Vocabulary\n",
    "        vocab = build_vocab_from_iterator(\n",
    "            yield_tokens(),\n",
    "            specials=special_tokens,\n",
    "            max_tokens=max_vocab_size\n",
    "        )\n",
    "\n",
    "        vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "        glove_vectors = GloVe(name='6B', dim=glove_dim)\n",
    "\n",
    "        embedding_matrix = torch.zeros(len(vocab), glove_dim)\n",
    "        for idx, token in enumerate(vocab.get_itos()):\n",
    "            if token in glove_vectors.stoi:\n",
    "                embedding_matrix[idx] = glove_vectors[token]\n",
    "            else:\n",
    "                embedding_matrix[idx] = torch.randn(glove_dim) * 0.1\n",
    "    else:\n",
    "        embedding_matrix = None\n",
    "\n",
    "    def encode(tokens):\n",
    "        return [vocab[token] for token in tokens]\n",
    "\n",
    "    # Apply encoding to the dataframe\n",
    "    df['context_idx'] = df['context_tok'].apply(encode)\n",
    "    df['question_idx'] = df['question_tok'].apply(encode)\n",
    "    df['answer_idx'] = df['answer_tok'].apply(\n",
    "        lambda x: [vocab['<sos>']] + encode(x) + [vocab['<eos>']]\n",
    "    )\n",
    "\n",
    "    return df, vocab, embedding_matrix\n",
    "\n",
    "train_df_sorted, vocab, embedding_matrix = preprocess_data(train_df_sorted)\n",
    "val_df_sorted, val_vocab, val_embedding_matrix = preprocess_data(val_df_sorted, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T21:33:50.582308Z",
     "iopub.status.busy": "2025-04-22T21:33:50.582005Z",
     "iopub.status.idle": "2025-04-22T21:33:50.607467Z",
     "shell.execute_reply": "2025-04-22T21:33:50.606814Z",
     "shell.execute_reply.started": "2025-04-22T21:33:50.582288Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context_tok</th>\n",
       "      <th>question_tok</th>\n",
       "      <th>answer_tok</th>\n",
       "      <th>context_idx</th>\n",
       "      <th>question_idx</th>\n",
       "      <th>answer_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12947</th>\n",
       "      <td>The Oklahoma School of Science and Mathematics...</td>\n",
       "      <td>Where is The Oklahoma School of Science and Ma...</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>[the, oklahoma, school, of, science, and, math...</td>\n",
       "      <td>[where, is, the, oklahoma, school, of, science...</td>\n",
       "      <td>[oklahoma, city]</td>\n",
       "      <td>[4, 543, 168, 6, 921, 9, 6027, 5, 11, 168, 18,...</td>\n",
       "      <td>[86, 13, 4, 543, 168, 6, 921, 9, 6027, 165, 12]</td>\n",
       "      <td>[1, 543, 39, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12697</th>\n",
       "      <td>In the past, the Malays used to call the Portu...</td>\n",
       "      <td>What does the term refer to now?</td>\n",
       "      <td>the modern Kristang creoles of Malaysia</td>\n",
       "      <td>[in, the, past, ,, the, malays, used, to, call...</td>\n",
       "      <td>[what, does, the, term, refer, to, now, ?]</td>\n",
       "      <td>[the, modern, kristang, creoles, of, malaysia]</td>\n",
       "      <td>[8, 4, 812, 5, 4, 3, 59, 10, 1012, 4, 609, 3, ...</td>\n",
       "      <td>[19, 105, 4, 147, 1280, 10, 200, 12]</td>\n",
       "      <td>[1, 4, 167, 3, 3, 6, 5439, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>In the past, the Malays used to call the Portu...</td>\n",
       "      <td>What term did the Malays use for the Portugues...</td>\n",
       "      <td>Nasrani</td>\n",
       "      <td>[in, the, past, ,, the, malays, used, to, call...</td>\n",
       "      <td>[what, term, did, the, malays, use, for, the, ...</td>\n",
       "      <td>[nasrani]</td>\n",
       "      <td>[8, 4, 812, 5, 4, 3, 59, 10, 1012, 4, 609, 3, ...</td>\n",
       "      <td>[19, 147, 44, 4, 3, 91, 18, 4, 609, 3, 12]</td>\n",
       "      <td>[1, 9724, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24533</th>\n",
       "      <td>New Delhi has been selected as one of the hund...</td>\n",
       "      <td>What is one Indian city that has been selected...</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>[new, delhi, has, been, selected, as, one, of,...</td>\n",
       "      <td>[what, is, one, indian, city, that, has, been,...</td>\n",
       "      <td>[new, delhi]</td>\n",
       "      <td>[42, 364, 36, 56, 2738, 15, 50, 6, 4, 2061, 58...</td>\n",
       "      <td>[19, 13, 50, 586, 39, 24, 36, 56, 2738, 10, 35...</td>\n",
       "      <td>[1, 42, 364, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24531</th>\n",
       "      <td>New Delhi has been selected as one of the hund...</td>\n",
       "      <td>What is the name of the mission to develop Ind...</td>\n",
       "      <td>Smart Cities Mission</td>\n",
       "      <td>[new, delhi, has, been, selected, as, one, of,...</td>\n",
       "      <td>[what, is, the, name, of, the, mission, to, de...</td>\n",
       "      <td>[smart, cities, mission]</td>\n",
       "      <td>[42, 364, 36, 56, 2738, 15, 50, 6, 4, 2061, 58...</td>\n",
       "      <td>[19, 13, 4, 107, 6, 4, 1749, 10, 1908, 586, 57...</td>\n",
       "      <td>[1, 5748, 384, 1749, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>Shortly after the unification of the region, t...</td>\n",
       "      <td>Who fled with the Jin court to the South?</td>\n",
       "      <td>nobles and wealthy families</td>\n",
       "      <td>[shortly, after, the, unification, of, the, re...</td>\n",
       "      <td>[who, fled, with, the, jin, court, to, the, so...</td>\n",
       "      <td>[nobles, and, wealthy, families]</td>\n",
       "      <td>[2664, 64, 4, 6816, 6, 4, 193, 5, 4, 202, 3982...</td>\n",
       "      <td>[43, 6941, 21, 4, 3982, 266, 10, 4, 128, 12]</td>\n",
       "      <td>[1, 4057, 9, 3378, 764, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78307</th>\n",
       "      <td>In September 1940, Japan decided to cut China'...</td>\n",
       "      <td>Who controled Indochina in 1940?</td>\n",
       "      <td>Vichy France</td>\n",
       "      <td>[in, september, 1940, ,, japan, decided, to, c...</td>\n",
       "      <td>[who, controled, indochina, in, 1940, ?]</td>\n",
       "      <td>[vichy, france]</td>\n",
       "      <td>[8, 331, 2163, 5, 565, 1253, 10, 1533, 145, 23...</td>\n",
       "      <td>[43, 3, 5851, 8, 2163, 12]</td>\n",
       "      <td>[1, 7870, 257, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78308</th>\n",
       "      <td>In September 1940, Japan decided to cut China'...</td>\n",
       "      <td>Who were the Axis Powers along with Japan in 1...</td>\n",
       "      <td>Germany and Italy</td>\n",
       "      <td>[in, september, 1940, ,, japan, decided, to, c...</td>\n",
       "      <td>[who, were, the, axis, powers, along, with, ja...</td>\n",
       "      <td>[germany, and, italy]</td>\n",
       "      <td>[8, 331, 2163, 5, 565, 1253, 10, 1533, 145, 23...</td>\n",
       "      <td>[43, 31, 4, 5385, 861, 179, 21, 565, 8, 2163, 12]</td>\n",
       "      <td>[1, 408, 9, 910, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40910</th>\n",
       "      <td>Incandescent light bulbs consist of an air-tig...</td>\n",
       "      <td>What function do small wires in a light bulb's...</td>\n",
       "      <td>Small wires embedded in the stem in turn suppo...</td>\n",
       "      <td>[incandescent, light, bulbs, consist, of, an, ...</td>\n",
       "      <td>[what, function, do, small, wires, in, a, ligh...</td>\n",
       "      <td>[small, wires, embedded, in, the, stem, in, tu...</td>\n",
       "      <td>[2699, 396, 4311, 2222, 6, 34, 3, 3358, 13032,...</td>\n",
       "      <td>[19, 1396, 115, 285, 4298, 8, 11, 396, 5258, 2...</td>\n",
       "      <td>[1, 285, 4298, 4621, 8, 4, 5091, 8, 1554, 338,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40908</th>\n",
       "      <td>Incandescent light bulbs consist of an air-tig...</td>\n",
       "      <td>How many conductors are present in the bulb's ...</td>\n",
       "      <td>two (or more)</td>\n",
       "      <td>[incandescent, light, bulbs, consist, of, an, ...</td>\n",
       "      <td>[how, many, conductors, are, present, in, the,...</td>\n",
       "      <td>[two, (, or, more, )]</td>\n",
       "      <td>[2699, 396, 4311, 2222, 6, 34, 3, 3358, 13032,...</td>\n",
       "      <td>[66, 49, 12910, 25, 588, 8, 4, 5258, 23, 699, 12]</td>\n",
       "      <td>[1, 70, 17, 30, 62, 16, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 context  \\\n",
       "12947  The Oklahoma School of Science and Mathematics...   \n",
       "12697  In the past, the Malays used to call the Portu...   \n",
       "12696  In the past, the Malays used to call the Portu...   \n",
       "24533  New Delhi has been selected as one of the hund...   \n",
       "24531  New Delhi has been selected as one of the hund...   \n",
       "...                                                  ...   \n",
       "16850  Shortly after the unification of the region, t...   \n",
       "78307  In September 1940, Japan decided to cut China'...   \n",
       "78308  In September 1940, Japan decided to cut China'...   \n",
       "40910  Incandescent light bulbs consist of an air-tig...   \n",
       "40908  Incandescent light bulbs consist of an air-tig...   \n",
       "\n",
       "                                                question  \\\n",
       "12947  Where is The Oklahoma School of Science and Ma...   \n",
       "12697                  What does the term refer to now?    \n",
       "12696  What term did the Malays use for the Portugues...   \n",
       "24533  What is one Indian city that has been selected...   \n",
       "24531  What is the name of the mission to develop Ind...   \n",
       "...                                                  ...   \n",
       "16850          Who fled with the Jin court to the South?   \n",
       "78307                   Who controled Indochina in 1940?   \n",
       "78308  Who were the Axis Powers along with Japan in 1...   \n",
       "40910  What function do small wires in a light bulb's...   \n",
       "40908  How many conductors are present in the bulb's ...   \n",
       "\n",
       "                                                  answer  \\\n",
       "12947                                      Oklahoma City   \n",
       "12697            the modern Kristang creoles of Malaysia   \n",
       "12696                                            Nasrani   \n",
       "24533                                          New Delhi   \n",
       "24531                               Smart Cities Mission   \n",
       "...                                                  ...   \n",
       "16850                        nobles and wealthy families   \n",
       "78307                                       Vichy France   \n",
       "78308                                  Germany and Italy   \n",
       "40910  Small wires embedded in the stem in turn suppo...   \n",
       "40908                                      two (or more)   \n",
       "\n",
       "                                             context_tok  \\\n",
       "12947  [the, oklahoma, school, of, science, and, math...   \n",
       "12697  [in, the, past, ,, the, malays, used, to, call...   \n",
       "12696  [in, the, past, ,, the, malays, used, to, call...   \n",
       "24533  [new, delhi, has, been, selected, as, one, of,...   \n",
       "24531  [new, delhi, has, been, selected, as, one, of,...   \n",
       "...                                                  ...   \n",
       "16850  [shortly, after, the, unification, of, the, re...   \n",
       "78307  [in, september, 1940, ,, japan, decided, to, c...   \n",
       "78308  [in, september, 1940, ,, japan, decided, to, c...   \n",
       "40910  [incandescent, light, bulbs, consist, of, an, ...   \n",
       "40908  [incandescent, light, bulbs, consist, of, an, ...   \n",
       "\n",
       "                                            question_tok  \\\n",
       "12947  [where, is, the, oklahoma, school, of, science...   \n",
       "12697         [what, does, the, term, refer, to, now, ?]   \n",
       "12696  [what, term, did, the, malays, use, for, the, ...   \n",
       "24533  [what, is, one, indian, city, that, has, been,...   \n",
       "24531  [what, is, the, name, of, the, mission, to, de...   \n",
       "...                                                  ...   \n",
       "16850  [who, fled, with, the, jin, court, to, the, so...   \n",
       "78307           [who, controled, indochina, in, 1940, ?]   \n",
       "78308  [who, were, the, axis, powers, along, with, ja...   \n",
       "40910  [what, function, do, small, wires, in, a, ligh...   \n",
       "40908  [how, many, conductors, are, present, in, the,...   \n",
       "\n",
       "                                              answer_tok  \\\n",
       "12947                                   [oklahoma, city]   \n",
       "12697     [the, modern, kristang, creoles, of, malaysia]   \n",
       "12696                                          [nasrani]   \n",
       "24533                                       [new, delhi]   \n",
       "24531                           [smart, cities, mission]   \n",
       "...                                                  ...   \n",
       "16850                   [nobles, and, wealthy, families]   \n",
       "78307                                    [vichy, france]   \n",
       "78308                              [germany, and, italy]   \n",
       "40910  [small, wires, embedded, in, the, stem, in, tu...   \n",
       "40908                              [two, (, or, more, )]   \n",
       "\n",
       "                                             context_idx  \\\n",
       "12947  [4, 543, 168, 6, 921, 9, 6027, 5, 11, 168, 18,...   \n",
       "12697  [8, 4, 812, 5, 4, 3, 59, 10, 1012, 4, 609, 3, ...   \n",
       "12696  [8, 4, 812, 5, 4, 3, 59, 10, 1012, 4, 609, 3, ...   \n",
       "24533  [42, 364, 36, 56, 2738, 15, 50, 6, 4, 2061, 58...   \n",
       "24531  [42, 364, 36, 56, 2738, 15, 50, 6, 4, 2061, 58...   \n",
       "...                                                  ...   \n",
       "16850  [2664, 64, 4, 6816, 6, 4, 193, 5, 4, 202, 3982...   \n",
       "78307  [8, 331, 2163, 5, 565, 1253, 10, 1533, 145, 23...   \n",
       "78308  [8, 331, 2163, 5, 565, 1253, 10, 1533, 145, 23...   \n",
       "40910  [2699, 396, 4311, 2222, 6, 34, 3, 3358, 13032,...   \n",
       "40908  [2699, 396, 4311, 2222, 6, 34, 3, 3358, 13032,...   \n",
       "\n",
       "                                            question_idx  \\\n",
       "12947    [86, 13, 4, 543, 168, 6, 921, 9, 6027, 165, 12]   \n",
       "12697               [19, 105, 4, 147, 1280, 10, 200, 12]   \n",
       "12696         [19, 147, 44, 4, 3, 91, 18, 4, 609, 3, 12]   \n",
       "24533  [19, 13, 50, 586, 39, 24, 36, 56, 2738, 10, 35...   \n",
       "24531  [19, 13, 4, 107, 6, 4, 1749, 10, 1908, 586, 57...   \n",
       "...                                                  ...   \n",
       "16850       [43, 6941, 21, 4, 3982, 266, 10, 4, 128, 12]   \n",
       "78307                         [43, 3, 5851, 8, 2163, 12]   \n",
       "78308  [43, 31, 4, 5385, 861, 179, 21, 565, 8, 2163, 12]   \n",
       "40910  [19, 1396, 115, 285, 4298, 8, 11, 396, 5258, 2...   \n",
       "40908  [66, 49, 12910, 25, 588, 8, 4, 5258, 23, 699, 12]   \n",
       "\n",
       "                                              answer_idx  \n",
       "12947                                    [1, 543, 39, 2]  \n",
       "12697                      [1, 4, 167, 3, 3, 6, 5439, 2]  \n",
       "12696                                       [1, 9724, 2]  \n",
       "24533                                    [1, 42, 364, 2]  \n",
       "24531                            [1, 5748, 384, 1749, 2]  \n",
       "...                                                  ...  \n",
       "16850                         [1, 4057, 9, 3378, 764, 2]  \n",
       "78307                                  [1, 7870, 257, 2]  \n",
       "78308                                [1, 408, 9, 910, 2]  \n",
       "40910  [1, 285, 4298, 4621, 8, 4, 5091, 8, 1554, 338,...  \n",
       "40908                         [1, 70, 17, 30, 62, 16, 2]  \n",
       "\n",
       "[20000 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFdG-NcICVu2"
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T21:36:26.444154Z",
     "iopub.status.busy": "2025-04-22T21:36:26.443820Z",
     "iopub.status.idle": "2025-04-22T21:36:27.256294Z",
     "shell.execute_reply": "2025-04-22T21:36:27.255563Z",
     "shell.execute_reply.started": "2025-04-22T21:36:26.444133Z"
    },
    "id": "ur23aL6o1L4x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def pad_seq(seq, max_len):\n",
    "    return seq + [vocab['<pad>']] * (max_len - len(seq))\n",
    "\n",
    "def collate_fn(batch):\n",
    "    context, question, answer = zip(*batch)\n",
    "    context_lens = [len(c) for c in context]\n",
    "    question_lens = [len(q) for q in question]\n",
    "    answer_lens = [len(a) for a in answer]\n",
    "\n",
    "    context_max = max(context_lens)\n",
    "    question_max = max(question_lens)\n",
    "    answer_max = max(answer_lens)\n",
    "\n",
    "    context_padded = [pad_seq(c, context_max) for c in context]\n",
    "    question_padded = [pad_seq(q, question_max) for q in question]\n",
    "    answer_padded = [pad_seq(a, answer_max) for a in answer]\n",
    "\n",
    "    return (torch.tensor(context_padded), torch.tensor(question_padded), torch.tensor(answer_padded))\n",
    "\n",
    "train_data = list(zip(train_df_sorted['context_idx'], train_df_sorted['question_idx'], train_df_sorted['answer_idx']))\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "val_data = list(zip(val_df_sorted['context_idx'], val_df_sorted['question_idx'], val_df_sorted['answer_idx']))\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOW-6Mt9CYkw"
   },
   "source": [
    "### Model (Encoder + Attention + Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T21:36:39.478202Z",
     "iopub.status.busy": "2025-04-22T21:36:39.477631Z",
     "iopub.status.idle": "2025-04-22T21:36:39.486243Z",
     "shell.execute_reply": "2025-04-22T21:36:39.485550Z",
     "shell.execute_reply.started": "2025-04-22T21:36:39.478178Z"
    },
    "id": "_V_HBu7o1ORU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n",
    "        self.gru = nn.GRU(embedding_matrix.size(1), hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        return outputs, hidden\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        hidden = hidden[-1].unsqueeze(1).repeat(1, encoder_outputs.size(1), 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.gru = nn.GRU(embedding_matrix.size(1) + hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.embedding(input)\n",
    "        attn_weights = self.attention(hidden, encoder_outputs).unsqueeze(1)\n",
    "        context = torch.bmm(attn_weights, encoder_outputs)\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "        output, hidden = self.gru(rnn_input, hidden)\n",
    "        prediction = self.fc(output.squeeze(1))\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAD71_ayCcDj"
   },
   "source": [
    "### Training Setup & Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T21:48:32.769039Z",
     "iopub.status.busy": "2025-04-22T21:48:32.768671Z",
     "iopub.status.idle": "2025-04-22T21:52:29.261597Z",
     "shell.execute_reply": "2025-04-22T21:52:29.260855Z",
     "shell.execute_reply.started": "2025-04-22T21:48:32.768998Z"
    },
    "executionInfo": {
     "elapsed": 2085303,
     "status": "ok",
     "timestamp": 1745188578504,
     "user": {
      "displayName": "Sherifa Hammoud",
      "userId": "01658453922136634541"
     },
     "user_tz": -120
    },
    "id": "VXooMzEc1QmL",
    "outputId": "4e5f982a-d5f0-423b-a0cc-4ca6413dcd0d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 5.9575, Token Accuracy: 0.2712\n",
      "Validation Loss: 5.1286, Validation Token Accuracy: 0.2693\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 5.2231, Token Accuracy: 0.2838\n",
      "Validation Loss: 5.0575, Validation Token Accuracy: 0.2727\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 4.9073, Token Accuracy: 0.2894\n",
      "Validation Loss: 4.9930, Validation Token Accuracy: 0.2780\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 4.5963, Token Accuracy: 0.2945\n",
      "Validation Loss: 4.9542, Validation Token Accuracy: 0.2830\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 4.2846, Token Accuracy: 0.3000\n",
      "Validation Loss: 4.9473, Validation Token Accuracy: 0.2877\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 3.9813, Token Accuracy: 0.3049\n",
      "Validation Loss: 4.9025, Validation Token Accuracy: 0.2978\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 3.6476, Token Accuracy: 0.3120\n",
      "Validation Loss: 4.9091, Validation Token Accuracy: 0.3161\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 3.3476, Token Accuracy: 0.3203\n",
      "Validation Loss: 4.9572, Validation Token Accuracy: 0.3059\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 3.0483, Token Accuracy: 0.3345\n",
      "Validation Loss: 4.9952, Validation Token Accuracy: 0.3128\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 2.7636, Token Accuracy: 0.3521\n",
      "Validation Loss: 5.0319, Validation Token Accuracy: 0.3120\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "enc = Encoder(embedding_matrix, hidden_dim=128).to(device)\n",
    "dec = Decoder(embedding_matrix, hidden_dim=128, vocab_size=len(vocab)).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(list(enc.parameters()) + list(dec.parameters()))\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab['<pad>'])\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    enc.train()\n",
    "    dec.train()\n",
    "    train_loss, total_tokens, correct_tokens = 0, 0, 0\n",
    "\n",
    "    for context, question, answer in train_loader:\n",
    "        context, question, answer = context.to(device), question.to(device), answer.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, hidden = enc(torch.cat((context, question), dim=1))\n",
    "        input_token = answer[:, 0]\n",
    "\n",
    "        loss = 0\n",
    "        for t in range(1, answer.size(1)):\n",
    "            output, hidden = dec(input_token, hidden, encoder_outputs)\n",
    "\n",
    "            # if train_loss == 0:\n",
    "                # print(f\"output: {output}\")\n",
    "                # print(f\"answer[:, t]: {answer[:, t]}\")\n",
    "                # print(f\"input_token: {input_token}\")\n",
    "                # print(f\"hidden: {hidden}\")\n",
    "                # print(f\"encoder_outputs: {encoder_outputs}\")\n",
    "                \n",
    "            # Calculate loss\n",
    "            loss += criterion(output, answer[:, t])\n",
    "\n",
    "            # Accuracy\n",
    "            predicted = output.argmax(dim=1)\n",
    "            mask = answer[:, t] != vocab['<pad>']\n",
    "            correct_tokens += (predicted == answer[:, t]).masked_select(mask).sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "            input_token = answer[:, t]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / answer.size(1)\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0\n",
    "    print(f\"\\nEpoch {epoch+1}\\nTraining Loss: {avg_loss:.4f}, Token Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    enc.eval()\n",
    "    dec.eval()\n",
    "    val_loss, total_tokens, correct_tokens = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for context, question, answer in val_loader:\n",
    "            context, question, answer = context.to(device), question.to(device), answer.to(device)\n",
    "\n",
    "            encoder_outputs, hidden = enc(torch.cat((context, question), dim=1))\n",
    "            input_token = answer[:, 0]\n",
    "\n",
    "            loss = 0\n",
    "            for t in range(1, answer.size(1)):\n",
    "                output, hidden = dec(input_token, hidden, encoder_outputs)\n",
    "                loss += criterion(output, answer[:, t])\n",
    "\n",
    "                # Accuracy\n",
    "                predicted = output.argmax(dim=1)\n",
    "                mask = answer[:, t] != vocab['<pad>']\n",
    "                correct_tokens += (predicted == answer[:, t]).masked_select(mask).sum().item()\n",
    "                total_tokens += mask.sum().item()\n",
    "\n",
    "                input_token = answer[:, t]\n",
    "\n",
    "            val_loss += loss.item() / answer.size(1)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Token Accuracy: {val_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "adtfwaAwCPq0",
    "BNL7-BZQCIJM",
    "62xRU1SMCBBk",
    "zFdG-NcICVu2",
    "qOW-6Mt9CYkw"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
